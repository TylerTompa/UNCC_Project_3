{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this project we will build a Machine Learning model to predict whether an indiviudal will have a stroke.  The data used in this project can be found on kaggle at the following link: https://www.kaggle.com/asaumya/healthcare-data#train_2v.csv\n",
    "\n",
    "# In this notebook, we build and implement our Machine Learning model.  To view our initial data analysis, please see the notebook titled \"Data_Analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file path to our data\n",
    "stoke_data_relevant_features_and_label_file_path = os.path.join(\"..\", \"Data\", \"stroke_data_relevant_features_and_label.csv\")\n",
    "\n",
    "# Create dataframe from local csv file \n",
    "stroke_data_relevant_features_and_label = pd.read_csv(stoke_data_relevant_features_and_label_file_path)\n",
    "\n",
    "# Previe dataframe\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to one hot encode our categorical columns, so we will convert each 0 to \"No,\" and each 1 to \"Yes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 0: 0\n",
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Before we replace 0 and 1 with \"no\" and \"yes\",\n",
    "# we should check to see if either of these numbers are present in the age column\n",
    "number_of_people_age_0 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 0])\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 0: {number_of_people_age_0}\")\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we replace all values of 0 and 1 with \"No\" and \"Yes,\"\n",
    "# we are going to replace ages of 1 with a value of \"Yes\"\n",
    "# We will also replace the binary data in the stroke column with strings.\n",
    "# We will therefore make copies of these rows to put back in the dataframe after our initial replacement\n",
    "\n",
    "copy_of_data = pd.DataFrame()\n",
    "\n",
    "# copy_of_data[\"age\"] = stroke_data_relevant_features_and_label[\"age\"]\n",
    "# copy_of_data[\"stroke\"] = stroke_data_relevant_features_and_label[\"stroke\"]\n",
    "\n",
    "copy_of_data_age = [stroke_data_relevant_features_and_label[\"age\"]]\n",
    "copy_of_data_stroke = [stroke_data_relevant_features_and_label[\"stroke\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n",
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace each 0 with \"No,\" and each 1 with \"Yes.\"\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(0, \"No\", inplace=True)\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(1, \"Yes\", inplace=True)\n",
    "\n",
    "# Preview dataframe after converting binary data to strings\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Check to see if either if the values of 1 in the age column were changed\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the values in the post-replacement age and stroke columns with the original values\n",
    "# stroke_data_relevant_features_and_label[\"age\"] = copy_of_data_age\n",
    "# stroke_data_relevant_features_and_label[\"stroke\"] = copy_of_data_stroke\n",
    "\n",
    "# # Preview dataframe to confirm values in stroke column were fixed\n",
    "# stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39339\n",
      "1     4061\n",
      "Name: hypertension, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    41338\n",
      "1     2062\n",
      "Name: heart_disease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm binary data proplerly converted\n",
    "print(stroke_data_relevant_features_and_label[\"hypertension\"].value_counts())\n",
    "print(100*\"-\")\n",
    "print(stroke_data_relevant_features_and_label[\"heart_disease\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>hypertension_0</th>\n",
       "      <th>hypertension_1</th>\n",
       "      <th>heart_disease_0</th>\n",
       "      <th>heart_disease_1</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>work_type_other</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  average_glucose_level   bmi  stroke  hypertension_0  hypertension_1  \\\n",
       "0   3.0                  95.12  18.0       0               1               0   \n",
       "1  58.0                  87.96  39.2       0               0               1   \n",
       "2   8.0                 110.89  17.6       0               1               0   \n",
       "3  70.0                  69.04  35.9       0               1               0   \n",
       "4  14.0                 161.28  19.1       0               1               0   \n",
       "\n",
       "   heart_disease_0  heart_disease_1  ever_married_No  ever_married_Yes  \\\n",
       "0                1                0                1                 0   \n",
       "1                1                0                0                 1   \n",
       "2                1                0                1                 0   \n",
       "3                1                0                0                 1   \n",
       "4                1                0                1                 0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  work_type_other  \\\n",
       "0                        0                   1                0   \n",
       "1                        0                   0                1   \n",
       "2                        0                   0                1   \n",
       "3                        0                   0                1   \n",
       "4                        0                   0                1   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               0                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               1                            0   \n",
       "4                               0                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to one hot encoded data\n",
    "machine_ready_stroke_data = pd.get_dummies(stroke_data_relevant_features_and_label, columns=[\"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"smoking_status\"])\n",
    "machine_ready_stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Maching Learning algorithms will we try out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features and label\n",
    "X = np.array(machine_ready_stroke_data.drop([\"stroke\"], axis=1))\n",
    "y = np.array(machine_ready_stroke_data[\"stroke\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our features and labels, but the data is still imbalanced.  We will try employing SMOTE to handle this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following section, we will run a for-loop to examine what order of SMOTE, split, scale (<em>SSS order</em>) yields the best results.  We will ignore any SSS order that scales before it splits, as this could bias the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE to handle the imbalanced data issue\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import tree to use the DecisionTreeClassifier() algorithm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Iteration 0\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9389258245339591\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9796082949308755\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.876036866359447\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9340372832746708\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9797235023041475\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8323732718894009\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9320166862208317\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9754608294930875\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8588709677419355\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9362534219788815\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9726958525345623\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8836405529953917\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 4\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.93690522748012\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9793778801843318\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.867626728110599\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 5\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9349498109764046\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9793778801843318\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.906221198156682\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 6\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9296701864163733\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9788018433179724\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8347926267281106\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 7\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9348846304262808\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9774193548387097\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8576036866359447\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 8\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9309086168687264\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9786866359447005\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8816820276497696\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 9\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9373614913309868\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9828341013824885\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8595622119815668\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "The most accurate order (highest average accuracy) is order 2, with an average accuracy of 0.9783986175115208\n",
      "The most stable order (lowest standard deviation) is order 2, with a standard deviation of 0.002731842987635571\n",
      "\n",
      "The least accurate order (least average accuracy) is order 3, with an average accuracy of 0.8658410138248848\n",
      "The least stable order (highest standard deviation) is order 3, with a standard deviation of 0.022473231806712936\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We want to determine which order of SMOTE, split, scale (SSS order) is best for this model\n",
    "# We will use the mean and stdev methods of the statistics library,\n",
    "# to find out which SSS order yields the highest average accuracy, and which order is the most stable (lowest standard deviation)\n",
    "from statistics import mean, stdev\n",
    "\n",
    "# Define variables holding the value for the each argument,\n",
    "# in order to easily change it in multiple places\n",
    "\n",
    "## SMOTE() parameters\n",
    "sampling_strategy_argument = 0.80\n",
    "k_neighbors_argument = 18\n",
    "\n",
    "## train_test_split() parameters\n",
    "test_size_argument = 0.2\n",
    "random_state_argument = 3\n",
    "\n",
    "## DecionTreeClassifier() parameters\n",
    "max_depth_argument = 30\n",
    "max_leaf_nodes_argument = 60\n",
    "\n",
    "# For every iteration in the loop,\n",
    "# we will append the accuracy of the current SSS order to it's own distinct list\n",
    "# After the loop has finished, we will calculate the average of each list\n",
    "# The list with the highest average we will call \"the most accuracte (on average)\"\n",
    "# we will also calculate the standard deviation of each list\n",
    "# The list with the lowest standard deviation we will call \"the most stable\"\n",
    "SSS_order_1_list = []\n",
    "SSS_order_2_list = []\n",
    "SSS_order_3_list = []\n",
    "\n",
    "# Define an iterator \n",
    "i = 1\n",
    "print(i)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    # Print the current iteration of the loop,\n",
    "    # in case we use a large number of iterations\n",
    "    print(f\"Iteration {i}\")\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"1. SMOTE, split, scale\")\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_SMOTE_train_scaled = X_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_scaler.transform(X_SMOTE_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_1 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 1\n",
    "    SSS_order_1_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "    \n",
    "####################################################################################################\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"2. split, SMOTE, scale\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_2 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 2\n",
    "    SSS_order_2_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"3. split, scale, SMOTE\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_3 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 3\n",
    "    SSS_order_3_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "    \n",
    "    # Print a long line with blank lines above and below,\n",
    "    # to easily see where one iteration of the loop ends, and the next starts\n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "    \n",
    "    # Increase the iterator by one\n",
    "    # so that the print statement at the beginning will show we're on the next iteration\n",
    "    i += 1\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Find the average accuracy of each SSS order,\n",
    "# and add each average to a list\n",
    "average_1 = mean(SSS_order_1_list)\n",
    "average_2 = mean(SSS_order_2_list)\n",
    "average_3 = mean(SSS_order_3_list)\n",
    "averages_list = [average_1, average_2, average_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest average accuracy\n",
    "if max(averages_list) == averages_list[0]:\n",
    "    most_accurate_order = 1\n",
    "    average_accuracy_greatest = averages_list[0]\n",
    "    \n",
    "elif max(averages_list) == averages_list[1]:\n",
    "    most_accurate_order = 2\n",
    "    average_accuracy_greatest = averages_list[1]\n",
    "    \n",
    "elif max(averages_list) == averages_list[2]:\n",
    "    most_accurate_order = 3\n",
    "    average_accuracy_greatest = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most accurate order (highest average accuracy) is order {most_accurate_order}, with an average accuracy of {average_accuracy_greatest}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Find the standard deviation of the accuracy of each SSS order,\n",
    "# and add each standard deviation to a list\n",
    "standard_deviation_1 = stdev(SSS_order_1_list)\n",
    "standard_deviation_2 = stdev(SSS_order_2_list)\n",
    "standard_deviation_3 = stdev(SSS_order_3_list)\n",
    "standard_deviations_list = [standard_deviation_1, standard_deviation_2, standard_deviation_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest standard deviation\n",
    "if min(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    most_stable_order = 1\n",
    "    lowest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    most_stable_order = 2\n",
    "    lowest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    most_stable_order = 3\n",
    "    lowest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most stable order (lowest standard deviation) is order {most_stable_order}, with a standard deviation of {lowest_standard_deviation}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Print a blank line to separate the lines showing us the \"best\" orders from the lines showing us the \"worst\" orders\n",
    "print()\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest average accuracy\n",
    "if min(averages_list) == averages_list[0]:\n",
    "    least_accurate_order = 1\n",
    "    average_accuracy_least = averages_list[0]\n",
    "    \n",
    "elif min(averages_list) == averages_list[1]:\n",
    "    least_accurate_order = 2\n",
    "    average_accuracy_least = averages_list[1]\n",
    "    \n",
    "elif min(averages_list) == averages_list[2]:\n",
    "    least_accurate_order = 3\n",
    "    average_accuracy_least = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least accurate order (least average accuracy) is order {least_accurate_order}, with an average accuracy of {average_accuracy_least}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest standard deviation\n",
    "if max(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    least_stable_order = 1\n",
    "    greatest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    least_stable_order = 2\n",
    "    greatest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    least_stable_order = 3\n",
    "    greatest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least stable order (highest standard deviation) is order {least_stable_order}, with a standard deviation of {greatest_standard_deviation}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a better idea of which SSS order is \"the best,\" we will try training and testing the model one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798387096774194\n"
     ]
    }
   ],
   "source": [
    " # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "    \n",
    "# Use SMOTE to handle class imbalance\n",
    "smote = SMOTE(sampling_strategy=0.2, k_neighbors=2)\n",
    "X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "# Create scaler for features\n",
    "X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "\n",
    "# Scale features\n",
    "X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "\n",
    "# Create, fit, and score the Decision Tree Classifier\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=30, max_leaf_nodes=60)\n",
    "classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "score = classifier.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out final model\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train_SMOTE)\n",
    "\n",
    "standard_scaler_export_file_path = os.path.join(\"..\", \"web_development\", \"standard_scaler.model\")\n",
    "joblib.dump(standard_scaler, standard_scaler_export_file_path)\n",
    "\n",
    "classifier_export_file_path = os.path.join(\"..\", \"web_development\", \"stroke_predictor.model\")\n",
    "pickle.dump(classifier, open(classifier_export_file_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# feature_names = [\"age\",\n",
    "#                  \"average_glucose_levels\",\n",
    "#                  \"bmi\",\n",
    "#                  \"hypertension_0\",\n",
    "#                  \"hypertension_1\",\n",
    "#                  \"heart_disease_0\",\n",
    "#                  \"heart_disease_1\",\n",
    "#                  \"ever_married_No\",\n",
    "#                  \"ever_married_Yes\",\n",
    "#                  \"work_type_Self-employed\",\n",
    "#                  \"work_type_children\",\n",
    "#                  \"work_type_other\",\n",
    "#                  \"smoking_status_formerly_smoked\",\n",
    "#                  \"smoking_status_never_smoked\",\n",
    "#                  \"smoking_status_smokes\"\n",
    "#                 ]\n",
    "# class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"]\n",
    "\n",
    "# dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "#                       feature_names=feature_names,\n",
    "#                       class_names=class_names,  \n",
    "#                       filled=True, rounded=True,  \n",
    "#                       special_characters=True)\n",
    "# graph = graphviz.Source(dot_data)  \n",
    "# graph "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
