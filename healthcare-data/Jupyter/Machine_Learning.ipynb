{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this project we will build a Machine Learning model to predict whether an indiviudal will have a stroke.  The data used in this project can be found on kaggle at the following link: https://www.kaggle.com/asaumya/healthcare-data#train_2v.csv\n",
    "\n",
    "# In this notebook, we build and implement our Machine Learning model.  To view our initial data analysis, please see the notebook titled \"Data_Analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file path to our data\n",
    "stoke_data_relevant_features_and_label_file_path = os.path.join(\"..\", \"Data\", \"stroke_data_relevant_features_and_label.csv\")\n",
    "\n",
    "# Create dataframe from local csv file \n",
    "stroke_data_relevant_features_and_label = pd.read_csv(stoke_data_relevant_features_and_label_file_path)\n",
    "\n",
    "# Previe dataframe\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to one hot encode our categorical columns, so we will convert each 0 to \"No,\" and each 1 to \"Yes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 0: 0\n",
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Before we replace 0 and 1 with \"no\" and \"yes\",\n",
    "# we should check to see if either of these numbers are present in the age column\n",
    "number_of_people_age_0 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 0])\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 0: {number_of_people_age_0}\")\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we replace all values of 0 and 1 with \"No\" and \"Yes,\"\n",
    "# we are going to replace ages of 1 with a value of \"Yes\"\n",
    "# We will also replace the binary data in the stroke column with strings.\n",
    "# We will therefore make copies of these rows to put back in the dataframe after our initial replacement\n",
    "\n",
    "copy_of_data = pd.DataFrame()\n",
    "\n",
    "# copy_of_data[\"age\"] = stroke_data_relevant_features_and_label[\"age\"]\n",
    "# copy_of_data[\"stroke\"] = stroke_data_relevant_features_and_label[\"stroke\"]\n",
    "\n",
    "copy_of_data_age = [stroke_data_relevant_features_and_label[\"age\"]]\n",
    "copy_of_data_stroke = [stroke_data_relevant_features_and_label[\"stroke\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace each 0 with \"No,\" and each 1 with \"Yes.\"\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(0, \"No\", inplace=True)\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(1, \"Yes\", inplace=True)\n",
    "\n",
    "# Preview dataframe after converting binary data to strings\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Check to see if either if the values of 1 in the age column were changed\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the values in the post-replacement age and stroke columns with the original values\n",
    "# stroke_data_relevant_features_and_label[\"age\"] = copy_of_data_age\n",
    "# stroke_data_relevant_features_and_label[\"stroke\"] = copy_of_data_stroke\n",
    "\n",
    "# # Preview dataframe to confirm values in stroke column were fixed\n",
    "# stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39339\n",
      "1     4061\n",
      "Name: hypertension, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    41338\n",
      "1     2062\n",
      "Name: heart_disease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm binary data proplerly converted\n",
    "print(stroke_data_relevant_features_and_label[\"hypertension\"].value_counts())\n",
    "print(100*\"-\")\n",
    "print(stroke_data_relevant_features_and_label[\"heart_disease\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>hypertension_0</th>\n",
       "      <th>hypertension_1</th>\n",
       "      <th>heart_disease_0</th>\n",
       "      <th>heart_disease_1</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>work_type_other</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  average_glucose_level   bmi  stroke  hypertension_0  hypertension_1  \\\n",
       "0   3.0                  95.12  18.0       0               1               0   \n",
       "1  58.0                  87.96  39.2       0               0               1   \n",
       "2   8.0                 110.89  17.6       0               1               0   \n",
       "3  70.0                  69.04  35.9       0               1               0   \n",
       "4  14.0                 161.28  19.1       0               1               0   \n",
       "\n",
       "   heart_disease_0  heart_disease_1  ever_married_No  ever_married_Yes  \\\n",
       "0                1                0                1                 0   \n",
       "1                1                0                0                 1   \n",
       "2                1                0                1                 0   \n",
       "3                1                0                0                 1   \n",
       "4                1                0                1                 0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  work_type_other  \\\n",
       "0                        0                   1                0   \n",
       "1                        0                   0                1   \n",
       "2                        0                   0                1   \n",
       "3                        0                   0                1   \n",
       "4                        0                   0                1   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               0                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               1                            0   \n",
       "4                               0                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to one hot encoded data\n",
    "machine_ready_stroke_data = pd.get_dummies(stroke_data_relevant_features_and_label, columns=[\"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"smoking_status\"])\n",
    "machine_ready_stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Maching Learning algorithms will we try out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features and label\n",
    "X = np.array(machine_ready_stroke_data.drop([\"stroke\"], axis=1))\n",
    "y = np.array(machine_ready_stroke_data[\"stroke\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our features and labels, but the data is still imbalanced.  We will try employing SMOTE to handle this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following section, we will try running several loops to see what the effect of changing several parameters is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE to handle the imbalanced data issue\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import tree to use the DecisionTreeClassifier() algorithm\n",
    "from sklearn import tree\n",
    "\n",
    "# Import StandardScaler to scale our data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the SMOTE parameter sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.03064516129032258\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.7888248847926267\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.7960684117217646\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.7890322580645162\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.7844926478256335\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.025230414746543778\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.7684331797235023\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.7767754718948795\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016474654377880184\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.811705069124424\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.7949734070288873\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.025230414746543778\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.7678571428571429\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.8197413703201585\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8119815668202764\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.7951298362707269\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Order number 5 was the most accurate the highest number of times.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "# average_accuracies = []\n",
    "# most_accurate_orders = []\n",
    "# most_stable_orders = []\n",
    "# standard_deviations = []\n",
    "\n",
    "sampling_strategy_argument = 0.80\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"1. split, SMOTE, scale\")\n",
    "    accuracies_list = []\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_train_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    X_test_scaler = StandardScaler().fit(X_test)\n",
    "#     y_scaler = StandardScaler().fit(y_train_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_train_SMOTE_scaled = X_train_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_test_scaler.transform(X_test)\n",
    "#     y_train_SMOTE_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"2. split, scale, SMOTE\")\n",
    "    scores = []\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_train_scaler = StandardScaler().fit(X_train)\n",
    "    X_test_scaler = StandardScaler().fit(X_test)\n",
    "#     y_scaler = StandardScaler().fit(y_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_train_scaled = X_train_scaler.transform(X_train)\n",
    "    X_test_scaled = X_test_scaler.transform(X_test)\n",
    "#     y_train_scaled = y_scaler.transform(y_train)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"3. SMOTE, split, scale\")\n",
    "    scores = []\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, random_state=3)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_SMOTE_train_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaler = StandardScaler().fit(X_SMOTE_test)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_SMOTE_train_scaled = X_SMOTE_train_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_SMOTE_test_scaler.transform(X_SMOTE_test)\n",
    "#     y_SMOTE_train_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "        \n",
    "    print(\"4. SMOTE, scale, split\")\n",
    "    scores = []\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_SMOTE_scaled = X_scaler.transform(X_SMOTE)\n",
    "#     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_scaled_train, X_SMOTE_scaled_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE_scaled, y_SMOTE, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_SMOTE_scaled_train, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "\n",
    "    print(\"5. scale, split, SMOTE\")\n",
    "    scores = []\n",
    "        \n",
    "    # Create scaler for features and label\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_scaled = X_scaler.transform(X)\n",
    "#     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y, random_state=3)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "    X_scaled_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_scaled_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_scaled_train_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_scaled_test, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"6. scale, SMOTE, split\")\n",
    "    scores = []\n",
    "        \n",
    "    # Create scaler for features and label\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_scaled = X_scaler.transform(X)\n",
    "#     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=4)\n",
    "    X_scaled_SMOTE, y_SMOTE = smote.fit_sample(X_scaled, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_scaled_SMOTE_train, X_scaled_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_scaled_SMOTE, y_SMOTE, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_scaled_SMOTE_train, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_scaled_SMOTE_test, y_SMOTE_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")  \n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "\n",
    "    if max(average_accuracies) == average_accuracies[0]:\n",
    "        print(\"Most accurate order (on average) is 1: split, SMOTE, scale\")\n",
    "#         most_accurate_orders.append(1)\n",
    "        most_accurate_order = 1\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[1]:\n",
    "        print(\"Most accurate order (on average) is 2: split, scale, SMOTE\")\n",
    "#         most_accurate_orders.append(2)\n",
    "        most_accurate_order = 2\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[2]:\n",
    "        print(\"Most accurate order (on average) is 3: SMOTE, split, scale\")\n",
    "#         most_accurate_orders.append(3)\n",
    "        most_accurate_order = 3\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[3]:\n",
    "        print(\"Most accurate order (on average) is 4: SMOTE, scale, split\")\n",
    "#         most_accurate_orders.append(4)\n",
    "        most_accurate_order = 4\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[4]:\n",
    "        print(\"Most accurate order (on average) is 5: scale, split, SMOTE\")\n",
    "#         most_accurate_orders.append(5)\n",
    "        most_accurate_order = 5\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[5]:\n",
    "        print(\"Most accurate order (on average) is 6: scale, SMOTE, split\")\n",
    "#         most_accurate_orders.append(6)\n",
    "        most_accurate_order = 6\n",
    "        \n",
    "print(f\"Order number {most_accurate_order} was the most accurate the highest number of times.\")\n",
    "# print(f\"Order number {} was the most stable (lowest standard deviation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025230414746543778,\n",
       " 0.7678571428571429,\n",
       " 0.8197413703201585,\n",
       " 0.016359447004608296,\n",
       " 0.8119815668202764,\n",
       " 0.7951298362707269]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. split, SMOTE, scale\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.07085253456221198\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.03179723502304147\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.028110599078341014\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.026382488479262674\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.026382488479262674\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.026382488479262674\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.4618663594470046\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.02453917050691244\n",
      "Average accuracy: 0.08703917050691244\n",
      "Standard Deviation of accuracy: 0.1424015563215359\n",
      "\n",
      "2. split, scale, SMOTE\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.8040322580645162\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7756912442396313\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7982718894009216\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7677419354838709\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7676267281105991\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7690092165898618\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.7671658986175115\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7056451612903226\n",
      "Average accuracy: 0.7693980414746544\n",
      "Standard Deviation of accuracy: 0.027722454956031713\n",
      "\n",
      "3. SMOTE, split, scale\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.7860034023581862\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.8003981797497156\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7565702296819788\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.478626977742022\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.8042548753780373\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7990969509410989\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.8024996295015561\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.799720831728918\n",
      "Average accuracy: 0.7533963846351892\n",
      "Standard Deviation of accuracy: 0.10488857033886423\n",
      "\n",
      "4. SMOTE, scale, split\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.016359447004608296\n",
      "Average accuracy: 0.016359447004608296\n",
      "Standard Deviation of accuracy: 0.0\n",
      "\n",
      "5. scale, split, SMOTE\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.8186175115207374\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.8139170506912442\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7840552995391705\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.811889400921659\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7892165898617511\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.6980645161290323\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.811705069124424\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.8139170506912442\n",
      "Average accuracy: 0.7926728110599078\n",
      "Standard Deviation of accuracy: 0.037656678573472706\n",
      "\n",
      "6. scale, SMOTE, split\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.7955065407403062\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7902730375426621\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.787047261484099\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7984446232233843\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7880905203879445\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7899142610724976\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.7929654695450279\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7947150558336542\n",
      "Average accuracy: 0.7921195962286969\n",
      "Standard Deviation of accuracy: 0.003693991504125649\n",
      "\n",
      "\n",
      "Most accurate order (on average) is 5: scale, split, SMOTE\n",
      "1. split, SMOTE, scale\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.03294930875576037\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.026382488479262674\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.03179723502304147\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.026382488479262674\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.025230414746543778\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.02891705069124424\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.4618663594470046\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.023847926267281105\n",
      "Average accuracy: 0.08217165898617512\n",
      "Standard Deviation of accuracy: 0.14354153031441358\n",
      "\n",
      "2. split, scale, SMOTE\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.8108294930875576\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7799539170506913\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.791705069124424\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7683179723502304\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7526497695852534\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7678571428571429\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.7671658986175115\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7670506912442396\n",
      "Average accuracy: 0.7756912442396313\n",
      "Standard Deviation of accuracy: 0.016967977229737016\n",
      "\n",
      "3. SMOTE, split, scale\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.8064175514753329\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7804891922639363\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7923476148409894\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7600965406275141\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7629054124517677\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.8003652782710162\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.807143209998518\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7985175202156334\n",
      "Average accuracy: 0.7885352900180885\n",
      "Standard Deviation of accuracy: 0.017501964543993588\n",
      "\n",
      "4. SMOTE, scale, split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.016474654377880184\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.016359447004608296\n",
      "Average accuracy: 0.016373847926267282\n",
      "Standard Deviation of accuracy: 3.810125735980074e-05\n",
      "\n",
      "5. scale, split, SMOTE\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.8138248847926267\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.8468202764976959\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.811705069124424\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.6980645161290323\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.811889400921659\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.6980645161290323\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.8119815668202764\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.6952073732718894\n",
      "Average accuracy: 0.7734447004608295\n",
      "Standard Deviation of accuracy: 0.06013204123372531\n",
      "\n",
      "6. scale, SMOTE, split\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.795037249956004\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7964732650739477\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7937831272084805\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7937248592115849\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7945562623839817\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7873268733194663\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.7895568838610878\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7956777050442818\n",
      "Average accuracy: 0.7932670282573543\n",
      "Standard Deviation of accuracy: 0.002966768149603399\n",
      "\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.03294930875576037\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.03179723502304147\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.03064516129032258\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.03064516129032258\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.02891705069124424\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.48986175115207375\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.4618663594470046\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.44873271889400923\n",
      "Average accuracy: 0.1944268433179724\n",
      "Standard Deviation of accuracy: 0.21125899737057874\n",
      "\n",
      "2. split, scale, SMOTE\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.7800691244239631\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7975806451612903\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7692396313364055\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7949308755760369\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7694700460829493\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7687788018433179\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.7678571428571429\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7682027649769585\n",
      "Average accuracy: 0.7770161290322581\n",
      "Standard Deviation of accuracy: 0.01172599412335227\n",
      "\n",
      "3. SMOTE, split, scale\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.7476975420895172\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7955062571103527\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7925684628975265\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.4285331187986055\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.798258421107519\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7654609101516919\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.8012646346885343\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.8135348479014247\n",
      "Average accuracy: 0.7428530243431465\n",
      "Standard Deviation of accuracy: 0.12044354020724335\n",
      "\n",
      "4. SMOTE, scale, split\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.02857142857142857\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.016359447004608296\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.016359447004608296\n",
      "Average accuracy: 0.01788594470046083\n",
      "Standard Deviation of accuracy: 0.00403873328013892\n",
      "\n",
      "5. scale, split, SMOTE\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.811889400921659\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.8141013824884793\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.811705069124424\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.811889400921659\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.8119815668202764\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.8468202764976959\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.6980645161290323\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7452534562211982\n",
      "Average accuracy: 0.793963133640553\n",
      "Standard Deviation of accuracy: 0.04479222373754352\n",
      "\n",
      "6. scale, SMOTE, split\n",
      "Setting the sampling_strategy parameter to 0.6 yields an accuracy of 0.8002581099313663\n",
      "Setting the sampling_strategy parameter to 0.65 yields an accuracy of 0.7907849829351535\n",
      "Setting the sampling_strategy parameter to 0.7000000000000001 yields an accuracy of 0.7925132508833922\n",
      "Setting the sampling_strategy parameter to 0.7500000000000001 yields an accuracy of 0.7964601769911505\n",
      "Setting the sampling_strategy parameter to 0.8000000000000002 yields an accuracy of 0.7920012514339347\n",
      "Setting the sampling_strategy parameter to 0.8500000000000002 yields an accuracy of 0.7915884531479884\n",
      "Setting the sampling_strategy parameter to 0.9000000000000002 yields an accuracy of 0.7938052660178827\n",
      "Setting the sampling_strategy parameter to 0.9500000000000003 yields an accuracy of 0.7939449364651521\n",
      "Average accuracy: 0.7939195534757526\n",
      "Standard Deviation of accuracy: 0.0029060906434630377\n",
      "\n",
      "\n",
      "Order number 5 was the most accurate the highest number of times.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "average_accuracies = []\n",
    "most_accurate_orders = []\n",
    "most_stable_orders = []\n",
    "standard_deviations = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"1. split, SMOTE, scale\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "        X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_train_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "        X_test_scaler = StandardScaler().fit(X_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_train_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_train_SMOTE_scaled = X_train_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "        X_test_scaled = X_test_scaler.transform(X_test)\n",
    "    #     y_train_SMOTE_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_test_scaled, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "    #     # Create, fit, and score the decision tree classifier\n",
    "    #     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    #     classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    #     score = classifier.score(X_smote_test, y_smote_test)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"2. split, scale, SMOTE\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_train_scaler = StandardScaler().fit(X_train)\n",
    "        X_test_scaler = StandardScaler().fit(X_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_train)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_train_scaled = X_train_scaler.transform(X_train)\n",
    "        X_test_scaled = X_test_scaler.transform(X_test)\n",
    "    #     y_train_scaled = y_scaler.transform(y_train)\n",
    "\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "        X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_test_scaled, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"3. SMOTE, split, scale\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_SMOTE_train_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "        X_SMOTE_test_scaler = StandardScaler().fit(X_SMOTE_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE_train)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_SMOTE_train_scaled = X_SMOTE_train_scaler.transform(X_SMOTE_train)\n",
    "        X_SMOTE_test_scaled = X_SMOTE_test_scaler.transform(X_SMOTE_test)\n",
    "    #     y_SMOTE_train_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "        \n",
    "    print(\"4. SMOTE, scale, split\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X_SMOTE)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_SMOTE_scaled = X_scaler.transform(X_SMOTE)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_SMOTE_scaled_train, X_SMOTE_scaled_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE_scaled, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_SMOTE_scaled_train, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "\n",
    "    print(\"5. scale, split, SMOTE\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_scaled = X_scaler.transform(X)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y, random_state=3)\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_scaled_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_scaled_train, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_scaled_train_SMOTE, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_scaled_test, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"6. scale, SMOTE, split\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_scaled = X_scaler.transform(X)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_scaled_SMOTE, y_SMOTE = smote.fit_sample(X_scaled, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_scaled_SMOTE_train, X_scaled_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_scaled_SMOTE, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_scaled_SMOTE_train, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_scaled_SMOTE_test, y_SMOTE_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")  \n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    print()\n",
    "\n",
    "    if max(average_accuracies) == average_accuracies[0]:\n",
    "        print(\"Most accurate order (on average) is 1: split, SMOTE, scale\")\n",
    "#         most_accurate_orders.append(1)\n",
    "        most_accurate_order = 1\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[1]:\n",
    "        print(\"Most accurate order (on average) is 2: split, scale, SMOTE\")\n",
    "#         most_accurate_orders.append(2)\n",
    "        most_accurate_order = 2\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[2]:\n",
    "        print(\"Most accurate order (on average) is 3: SMOTE, split, scale\")\n",
    "#         most_accurate_orders.append(3)\n",
    "        most_accurate_order = 3\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[3]:\n",
    "        print(\"Most accurate order (on average) is 4: SMOTE, scale, split\")\n",
    "#         most_accurate_orders.append(4)\n",
    "        most_accurate_order = 4\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[4]:\n",
    "        print(\"Most accurate order (on average) is 5: scale, split, SMOTE\")\n",
    "#         most_accurate_orders.append(5)\n",
    "        most_accurate_order = 5\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[5]:\n",
    "        print(\"Most accurate order (on average) is 6: scale, SMOTE, split\")\n",
    "#         most_accurate_orders.append(6)\n",
    "        most_accurate_order = 6\n",
    "        \n",
    "print(f\"Order number {most_accurate_order} was the most accurate the highest number of times.\")\n",
    "# print(f\"Order number {} was the most stable (lowest standard deviation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_accurate_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracies\n",
    "\n",
    "if max(average_accuracies) == average_accuracies[0]:\n",
    "    print(f\"Most accurate order is {1}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[1]:\n",
    "    print(f\"Most accurate order is {2}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[2]:\n",
    "    print(f\"Most accurate order is {3}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[3]:\n",
    "    print(f\"Most accurate order is {4}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[4]:\n",
    "    print(f\"Most accurate order is {5}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[5]:\n",
    "    print(f\"Most accurate order is {6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accuracte order after 10 tries: <br>\n",
    "1: 0 <br>\n",
    "2: 0 <br>\n",
    "3: 0 <br>\n",
    "4: 1 <br>\n",
    "5: 4 <br>\n",
    "6: 5 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "print(\"split, SMOTE, scale\")\n",
    "\n",
    "for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_smote, y_smote = smote.fit_sample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "#     y_smote_train.reshape(-1,1)\n",
    "#     y_smote_test.reshape(-1,1)\n",
    "\n",
    "#     X_smote_train = X_smote_train.reshape(-1,1)\n",
    "#     y_smote_train = y_smote_train.reshape(-1,1)\n",
    "#     X_smote_test = X_smote_test.reshape(-1,1)\n",
    "#     y_smote_test = y_smote_test.reshape(-1,1)\n",
    "    \n",
    "#     print(X_smote_train_scaled.shape)\n",
    "#     print(y_smote_train_scaled.shape)\n",
    "#     print(X_smote_test_scaled.shape)\n",
    "#     print(y_smote_test_scaled.shape)\n",
    "    \n",
    "    # Create scale for features and label\n",
    "    X_smote_scaler = StandardScaler().fit(X_smote_train)\n",
    "#     y_smote_scaler = StandardScaler().fit(y_smote_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_smote_train_scaled = X_smote_scaler.transform(X_smote_train)\n",
    "    X_smote_test_scaled = X_smote_scaler.transform(X_smote_test)\n",
    "#     y_smote_train_scaled = y_smote_scaler.transform(y_smote_train)\n",
    "#     y_smote_test_scaled = y_smote_scaler.transform(y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "#     classifier = classifier.fit(X=X_smote_train_scaled, y=y_smote_train)\n",
    "#     score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "# classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_smote, y_smote = smote.fit_sample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "#     y_smote_train.reshape(-1,1)\n",
    "#     y_smote_test.reshape(-1,1)\n",
    "\n",
    "#     X_smote_train = X_smote_train.reshape(-1,1)\n",
    "#     y_smote_train = y_smote_train.reshape(-1,1)\n",
    "#     X_smote_test = X_smote_test.reshape(-1,1)\n",
    "#     y_smote_test = y_smote_test.reshape(-1,1)\n",
    "    \n",
    "#     print(X_smote_train_scaled.shape)\n",
    "#     print(y_smote_train_scaled.shape)\n",
    "#     print(X_smote_test_scaled.shape)\n",
    "#     print(y_smote_test_scaled.shape)\n",
    "    \n",
    "    # Create scale for features and label\n",
    "    X_smote_scaler = StandardScaler().fit(X_smote_train)\n",
    "#     y_smote_scaler = StandardScaler().fit(y_smote_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_smote_train_scaled = X_smote_scaler.transform(X_smote_train)\n",
    "    X_smote_test_scaled = X_smote_scaler.transform(X_smote_test)\n",
    "#     y_smote_train_scaled = y_smote_scaler.transform(y_smote_train)\n",
    "#     y_smote_test_scaled = y_smote_scaler.transform(y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train_scaled, y=y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "#     classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "#     score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "# classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(machine_ready_stroke_data.corr(),cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix\n",
    "confusion_matrix(score,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the SMOTE parameter k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "k_neighbors_arguments = np.arange(1, 102, 10)\n",
    "\n",
    "for k_neighbors_argument in k_neighbors_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=k_neighbors_argument)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the k_neighbor parameter to {k_neighbors_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the train_test_split parameter test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "test_size_arguments = np.arange(0.05, 0.5, 0.05)\n",
    "\n",
    "for test_size_argument in test_size_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = test_size_argument, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the train_test_split parameter to {test_size_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the train_test_split parameter random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "random_state_arguments = np.arange(1, 10, 1)\n",
    "\n",
    "for random_state_argument in random_state_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the random_state parameter to {random_state_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier() parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the DecisionTreeClassifier() parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "max_depth_arguments = np.arange(1, 102, 10)\n",
    "\n",
    "for max_depth_argument in max_depth_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the max_depth parameter to {max_depth_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the DecisionTreeClassifier() parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "max_nodes_arguments = np.arange(2, 153, 10)\n",
    "\n",
    "for max_nodes_argument in max_nodes_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=max_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the max_node parameter to {max_nodes_argument} yields an accuracy of {score}\")\n",
    "\n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a better idea of what impact each parameter does, we will try one final test below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.85, k_neighbors=60)\n",
    "X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "\n",
    "y_smote = y_smote.reshape(-1,1)\n",
    "    \n",
    "# Split the data into training and testing sets\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "\n",
    "# Create, fit, and score the decision tree classifier\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=100, max_leaf_nodes=100)\n",
    "classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "score = classifier.score(X_smote_test, y_smote_test)\n",
    "\n",
    "print(score, \"\\n\")\n",
    "print(classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_smote)\n",
    "\n",
    "\n",
    "joblib.dump(standard_scaler, \"../web_development/standard_scaler.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "feature_names = [\"age\",\n",
    "                 \"average_glucose_levels\",\n",
    "                 \"bmi\",\n",
    "                 \"hypertension_0\",\n",
    "                 \"hypertension_1\",\n",
    "                 \"heart_disease_0\",\n",
    "                 \"heart_disease_1\",\n",
    "                 \"ever_married_No\",\n",
    "                 \"ever_married_Yes\",\n",
    "                 \"work_type_Self-employed\",\n",
    "                 \"work_type_children\",\n",
    "                 \"work_type_other\",\n",
    "                 \"smoking_status_formerly_smoked\",\n",
    "                 \"smoking_status_never_smoked\",\n",
    "                 \"smoking_status_smokes\"\n",
    "                ]\n",
    "class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"]\n",
    "\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                      feature_names=feature_names,\n",
    "                      class_names=class_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out final model\n",
    "import pickle\n",
    "\n",
    "file_name = \"../web_development/stroke_predictor.model\"\n",
    "pickle.dump(classifier, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create scale for features and label\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Scale features and labels\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = []\n",
    "# models.append((\"LR\", LogisticRegression()))\n",
    "# models.append((\"CART\", DecisionTreeClassifier()))\n",
    "# models.append((\"CART\", RandomForestClassifier()))\n",
    "# models.append((\"SVM\", SVC()))\n",
    "# models.append((\"NB\", GaussianNB()))\n",
    "\n",
    "# from sklearn import model_selection\n",
    "\n",
    "# # Evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "\n",
    "# for name, model in models:\n",
    "#     kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "#     cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(f\"{name}: {cv_results.mean()}, {cv_results.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at this\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# decision_tree_data = tree.export_graphviz(\n",
    "#   classifier,\n",
    "#   out_file=None,\n",
    "#   feature_names=[\"age\",\n",
    "#                  \"average_glucose_levels\",\n",
    "#                  \"bmi\",\n",
    "#                  \"hypertension_0\",\n",
    "#                  \"hypertension_1\",\n",
    "#                  \"heart_disease_0\",\n",
    "#                  \"heart_disease_1\",\n",
    "#                  \"ever_married_No\",\n",
    "#                  \"ever_married_Yes\",\n",
    "#                  \"work_type_Self-employed\",\n",
    "#                  \"work_type_children\",\n",
    "#                  \"work_type_other\",\n",
    "#                  \"smoking_status_formerly_smoked\",\n",
    "#                  \"smoking_status_never_smoked\",\n",
    "#                  \"smoking_status_smokes\"\n",
    "#                 ],\n",
    "#     class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"],\n",
    "#     filled=True,\n",
    "#     rounded=False\n",
    "# )\n",
    "\n",
    "# graph = graphviz.Source(decision_tree_data)\n",
    "# #graph\n",
    "\n",
    "# #graph[size=\"7.75,10.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "decision_tree_data = tree.export_graphviz(\n",
    "  classifier,\n",
    "  out_file=None,\n",
    "  feature_names=[\"age\",\n",
    "                 \"average_glucose_levels\",\n",
    "                 \"bmi\",\n",
    "                 \"hypertension_0\",\n",
    "                 \"hypertension_1\",\n",
    "                 \"heart_disease_0\",\n",
    "                 \"heart_disease_1\",\n",
    "                 \"ever_married_No\",\n",
    "                 \"ever_married_Yes\",\n",
    "                 \"work_type_Self-employed\",\n",
    "                 \"work_type_children\",\n",
    "                 \"work_type_other\",\n",
    "                 \"smoking_status_formerly_smoked\",\n",
    "                 \"smoking_status_never_smoked\",\n",
    "                 \"smoking_status_smokes\"\n",
    "                ],\n",
    "    class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"],\n",
    "    filled=True,\n",
    "    rounded=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "graph = graphviz.Source(decision_tree_data)\n",
    "graph\n",
    "\n",
    "#graph[size=\"7.75,10.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tree.export_graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.render(format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing both classes\n",
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=1)\n",
    "rf = rf.fit(X_train, np.array(y_train))\n",
    "rf.score(X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
