{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this project we will build a Machine Learning model to predict whether an indiviudal will have a stroke.  The data used in this project can be found on kaggle at the following link: https://www.kaggle.com/asaumya/healthcare-data#train_2v.csv\n",
    "\n",
    "# In this notebook, we build and implement our Machine Learning model.  To view our initial data analysis, please see the notebook titled \"Data_Analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file path to our data\n",
    "stoke_data_relevant_features_and_label_file_path = os.path.join(\"..\", \"Data\", \"stroke_data_relevant_features_and_label.csv\")\n",
    "\n",
    "# Create dataframe from local csv file \n",
    "stroke_data_relevant_features_and_label = pd.read_csv(stoke_data_relevant_features_and_label_file_path)\n",
    "\n",
    "# Previe dataframe\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to one hot encode our categorical columns, so we will convert each 0 to \"No,\" and each 1 to \"Yes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 0: 0\n",
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Before we replace 0 and 1 with \"no\" and \"yes\",\n",
    "# we should check to see if either of these numbers are present in the age column\n",
    "number_of_people_age_0 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 0])\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 0: {number_of_people_age_0}\")\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we replace all values of 0 and 1 with \"No\" and \"Yes,\"\n",
    "# we are going to replace ages of 1 with a value of \"Yes\"\n",
    "# We will also replace the binary data in the stroke column with strings.\n",
    "# We will therefore make copies of these rows to put back in the dataframe after our initial replacement\n",
    "\n",
    "copy_of_data = pd.DataFrame()\n",
    "\n",
    "# copy_of_data[\"age\"] = stroke_data_relevant_features_and_label[\"age\"]\n",
    "# copy_of_data[\"stroke\"] = stroke_data_relevant_features_and_label[\"stroke\"]\n",
    "\n",
    "copy_of_data_age = [stroke_data_relevant_features_and_label[\"age\"]]\n",
    "copy_of_data_stroke = [stroke_data_relevant_features_and_label[\"stroke\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n",
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace each 0 with \"No,\" and each 1 with \"Yes.\"\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(0, \"No\", inplace=True)\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(1, \"Yes\", inplace=True)\n",
    "\n",
    "# Preview dataframe after converting binary data to strings\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Check to see if either if the values of 1 in the age column were changed\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the values in the post-replacement age and stroke columns with the original values\n",
    "# stroke_data_relevant_features_and_label[\"age\"] = copy_of_data_age\n",
    "# stroke_data_relevant_features_and_label[\"stroke\"] = copy_of_data_stroke\n",
    "\n",
    "# # Preview dataframe to confirm values in stroke column were fixed\n",
    "# stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39339\n",
      "1     4061\n",
      "Name: hypertension, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    41338\n",
      "1     2062\n",
      "Name: heart_disease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm binary data proplerly converted\n",
    "print(stroke_data_relevant_features_and_label[\"hypertension\"].value_counts())\n",
    "print(100*\"-\")\n",
    "print(stroke_data_relevant_features_and_label[\"heart_disease\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>hypertension_0</th>\n",
       "      <th>hypertension_1</th>\n",
       "      <th>heart_disease_0</th>\n",
       "      <th>heart_disease_1</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>work_type_other</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  average_glucose_level   bmi  stroke  hypertension_0  hypertension_1  \\\n",
       "0   3.0                  95.12  18.0       0               1               0   \n",
       "1  58.0                  87.96  39.2       0               0               1   \n",
       "2   8.0                 110.89  17.6       0               1               0   \n",
       "3  70.0                  69.04  35.9       0               1               0   \n",
       "4  14.0                 161.28  19.1       0               1               0   \n",
       "\n",
       "   heart_disease_0  heart_disease_1  ever_married_No  ever_married_Yes  \\\n",
       "0                1                0                1                 0   \n",
       "1                1                0                0                 1   \n",
       "2                1                0                1                 0   \n",
       "3                1                0                0                 1   \n",
       "4                1                0                1                 0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  work_type_other  \\\n",
       "0                        0                   1                0   \n",
       "1                        0                   0                1   \n",
       "2                        0                   0                1   \n",
       "3                        0                   0                1   \n",
       "4                        0                   0                1   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               0                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               1                            0   \n",
       "4                               0                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to one hot encoded data\n",
    "machine_ready_stroke_data = pd.get_dummies(stroke_data_relevant_features_and_label, columns=[\"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"smoking_status\"])\n",
    "machine_ready_stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Maching Learning algorithms will we try out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features and label\n",
    "X = np.array(machine_ready_stroke_data.drop([\"stroke\"], axis=1))\n",
    "y = np.array(machine_ready_stroke_data[\"stroke\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our features and labels, but the data is still imbalanced.  We will try employing SMOTE to handle this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following section, we will try running several loops to see what the effect of changing several parameters is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE to handle the imbalanced data issue\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import tree to use the DecisionTreeClassifier() algorithm\n",
    "from sklearn import tree\n",
    "\n",
    "# Import StandardScaler to scale our data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the SMOTE parameter sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.03790322580645161\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.5383640552995391\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.8175596402033634\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8487327188940093\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.8736149133098683\n",
      "\n",
      "Most accurate order is 6: scale, SMOTE, split\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.26036866359447003\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.5285714285714286\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.7553122148350933\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8633640552995392\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.8831312736279494\n",
      "\n",
      "Most accurate order is 6: scale, SMOTE, split\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.27027649769585255\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.5779953917050691\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.7959196975622475\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8571428571428571\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.8698996219528092\n",
      "\n",
      "Most accurate order is 6: scale, SMOTE, split\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.027649769585253458\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.5435483870967742\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.7988528223178204\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8724654377880184\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.8690522748011993\n",
      "\n",
      "Most accurate order is 5: scale, split, SMOTE\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.2720046082949309\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.6733870967741935\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.7772780602268283\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8595622119815668\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.891604745144049\n",
      "\n",
      "Most accurate order is 6: scale, SMOTE, split\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. split, SMOTE, scale\n",
      "Accuracy: 0.03790322580645161\n",
      "2. split, scale, SMOTE\n",
      "Accuracy: 0.5799539170506912\n",
      "3. SMOTE, split, scale\n",
      "Accuracy: 0.8530178594707339\n",
      "4. SMOTE, scale, split\n",
      "Accuracy: 0.016359447004608296\n",
      "5. scale, split, SMOTE\n",
      "Accuracy: 0.8571428571428571\n",
      "6. scale, SMOTE, split\n",
      "Accuracy: 0.8920610089949159\n",
      "\n",
      "Most accurate order is 6: scale, SMOTE, split\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Order number 6 was the most accurate the highest number of times.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We want to determine which order of SMOTE, split, scale is best for this model\n",
    "# We will use the mode and stdev methods of the statistics library,\n",
    "# to find out which order yields the highest accuracy, and which order is the most stable (lowest standard deviation)\n",
    "from statistics import mode, stdev\n",
    "\n",
    "# most_stable_orders = []\n",
    "# standard_deviations = []\n",
    "\n",
    "# Define variables holding the value for the each argument,\n",
    "# in order to easily change it in multiple places\n",
    "\n",
    "## SMOTE() parameters\n",
    "sampling_strategy_argument = 0.80\n",
    "k_neighbors_argument = 18\n",
    "\n",
    "## train_test_split() parameters\n",
    "test_size_argument = 0.2\n",
    "random_state_argument = 3\n",
    "\n",
    "## DecionTreeClassifier() parameters\n",
    "max_depth_argument = 30\n",
    "max_leaf_nodes_argument = 60\n",
    "\n",
    "# For every iteration in the loop, we will store which value yielded the highest accuracy\n",
    "# After the loop has finished, we will calculate the mode of the list,\n",
    "# to determine which order yields the highest accuracy most often\n",
    "most_accurate_orders = []\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"1. split, SMOTE, scale\")\n",
    "    accuracies_list = []\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_train_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    X_test_scaler = StandardScaler().fit(X_test)\n",
    "#     y_scaler = StandardScaler().fit(y_train_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_train_SMOTE_scaled = X_train_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_test_scaler.transform(X_test)\n",
    "#     y_train_SMOTE_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"2. split, scale, SMOTE\")\n",
    "    scores = []\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_train_scaler = StandardScaler().fit(X_train)\n",
    "    X_test_scaler = StandardScaler().fit(X_test)\n",
    "#     y_scaler = StandardScaler().fit(y_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_train_scaled = X_train_scaler.transform(X_train)\n",
    "    X_test_scaled = X_test_scaler.transform(X_test)\n",
    "#     y_train_scaled = y_scaler.transform(y_train)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"3. SMOTE, split, scale\")\n",
    "    scores = []\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_SMOTE_train_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaler = StandardScaler().fit(X_SMOTE_test)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_SMOTE_train_scaled = X_SMOTE_train_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_SMOTE_test_scaler.transform(X_SMOTE_test)\n",
    "#     y_SMOTE_train_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "        \n",
    "    print(\"4. SMOTE, scale, split\")\n",
    "    scores = []\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features and label\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_SMOTE_scaled = X_scaler.transform(X_SMOTE)\n",
    "#     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_scaled_train, X_SMOTE_scaled_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE_scaled, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_scaled_train, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "\n",
    "    print(\"5. scale, split, SMOTE\")\n",
    "    scores = []\n",
    "        \n",
    "    # Create scaler for features and label\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_scaled = X_scaler.transform(X)\n",
    "#     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_scaled_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_scaled_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_scaled_train_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_scaled_test, y_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")\n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"6. scale, SMOTE, split\")\n",
    "    scores = []\n",
    "        \n",
    "    # Create scaler for features and label\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "#     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_scaled = X_scaler.transform(X)\n",
    "#     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_scaled_SMOTE, y_SMOTE = smote.fit_sample(X_scaled, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_scaled_SMOTE_train, X_scaled_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_scaled_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_scaled_SMOTE_train, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_scaled_SMOTE_test, y_SMOTE_test)\n",
    "    accuracies_list.append(score)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Accuracy: {score}\")  \n",
    "        \n",
    "#     average_accuracy = sum(scores)/len(scores)\n",
    "#     average_accuracies.append(average_accuracy)\n",
    "#     standard_deviation = np.std(scores)\n",
    "#     print(f\"Average accuracy: {average_accuracy}\")\n",
    "#     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    print()\n",
    "    \n",
    "    if max(accuracies_list) == accuracies_list[0]:\n",
    "        print(\"Most accurate order is 1: split, SMOTE, scale\")\n",
    "        most_accurate_orders.append(1)\n",
    "        \n",
    "    elif max(accuracies_list) == accuracies_list[1]:\n",
    "        print(\"Most accurate order is 2: split, scale, SMOTE\")\n",
    "        most_accurate_orders.append(2)\n",
    "        \n",
    "    elif max(accuracies_list) == accuracies_list[2]:\n",
    "        print(\"Most accurate order is 3: SMOTE, split, scale\")\n",
    "        most_accurate_orders.append(3)\n",
    "        \n",
    "    elif max(accuracies_list) == accuracies_list[3]:\n",
    "        print(\"Most accurate order is 4: SMOTE, scale, split\")\n",
    "        most_accurate_orders.append(4)\n",
    "        \n",
    "    elif max(accuracies_list) == accuracies_list[4]:\n",
    "        print(\"Most accurate order is 5: scale, split, SMOTE\")\n",
    "        most_accurate_orders.append(5)\n",
    "        \n",
    "    elif max(accuracies_list) == accuracies_list[5]:\n",
    "        print(\"Most accurate order is 6: scale, SMOTE, split\")\n",
    "        most_accurate_orders.append(6)\n",
    "    \n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "    \n",
    "most_accurate_order = mode(most_accurate_orders)        \n",
    "print(f\"Order number {most_accurate_order} was the most accurate the highest number of times.\")\n",
    "# print(f\"Order number {} was the most stable (lowest standard deviation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "\n",
    "stdev([1, 4, 6, 7, 3, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "average_accuracies = []\n",
    "most_accurate_orders = []\n",
    "most_stable_orders = []\n",
    "standard_deviations = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"1. split, SMOTE, scale\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "        X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_train_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "        X_test_scaler = StandardScaler().fit(X_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_train_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_train_SMOTE_scaled = X_train_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "        X_test_scaled = X_test_scaler.transform(X_test)\n",
    "    #     y_train_SMOTE_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_test_scaled, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "    #     # Create, fit, and score the decision tree classifier\n",
    "    #     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    #     classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    #     score = classifier.score(X_smote_test, y_smote_test)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"2. split, scale, SMOTE\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_train_scaler = StandardScaler().fit(X_train)\n",
    "        X_test_scaler = StandardScaler().fit(X_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_train)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_train_scaled = X_train_scaler.transform(X_train)\n",
    "        X_test_scaled = X_test_scaler.transform(X_test)\n",
    "    #     y_train_scaled = y_scaler.transform(y_train)\n",
    "\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "        X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_test_scaled, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"3. SMOTE, split, scale\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_SMOTE_train_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "        X_SMOTE_test_scaler = StandardScaler().fit(X_SMOTE_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE_train)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_SMOTE_train_scaled = X_SMOTE_train_scaler.transform(X_SMOTE_train)\n",
    "        X_SMOTE_test_scaled = X_SMOTE_test_scaler.transform(X_SMOTE_test)\n",
    "    #     y_SMOTE_train_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "        \n",
    "    print(\"4. SMOTE, scale, split\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X_SMOTE)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_SMOTE_scaled = X_scaler.transform(X_SMOTE)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_SMOTE_scaled_train, X_SMOTE_scaled_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE_scaled, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_SMOTE_scaled_train, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "\n",
    "    print(\"5. scale, split, SMOTE\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_scaled = X_scaler.transform(X)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y, random_state=3)\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_scaled_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_scaled_train, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_scaled_train_SMOTE, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_scaled_test, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"6. scale, SMOTE, split\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_scaled = X_scaler.transform(X)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_scaled_SMOTE, y_SMOTE = smote.fit_sample(X_scaled, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_scaled_SMOTE_train, X_scaled_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_scaled_SMOTE, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_scaled_SMOTE_train, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_scaled_SMOTE_test, y_SMOTE_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")  \n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    print()\n",
    "\n",
    "    if max(average_accuracies) == average_accuracies[0]:\n",
    "        print(\"Most accurate order (on average) is 1: split, SMOTE, scale\")\n",
    "#         most_accurate_orders.append(1)\n",
    "        most_accurate_order = 1\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[1]:\n",
    "        print(\"Most accurate order (on average) is 2: split, scale, SMOTE\")\n",
    "#         most_accurate_orders.append(2)\n",
    "        most_accurate_order = 2\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[2]:\n",
    "        print(\"Most accurate order (on average) is 3: SMOTE, split, scale\")\n",
    "#         most_accurate_orders.append(3)\n",
    "        most_accurate_order = 3\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[3]:\n",
    "        print(\"Most accurate order (on average) is 4: SMOTE, scale, split\")\n",
    "#         most_accurate_orders.append(4)\n",
    "        most_accurate_order = 4\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[4]:\n",
    "        print(\"Most accurate order (on average) is 5: scale, split, SMOTE\")\n",
    "#         most_accurate_orders.append(5)\n",
    "        most_accurate_order = 5\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[5]:\n",
    "        print(\"Most accurate order (on average) is 6: scale, SMOTE, split\")\n",
    "#         most_accurate_orders.append(6)\n",
    "        most_accurate_order = 6\n",
    "        \n",
    "print(f\"Order number {most_accurate_order} was the most accurate the highest number of times.\")\n",
    "# print(f\"Order number {} was the most stable (lowest standard deviation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracies\n",
    "\n",
    "if max(average_accuracies) == average_accuracies[0]:\n",
    "    print(f\"Most accurate order is {1}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[1]:\n",
    "    print(f\"Most accurate order is {2}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[2]:\n",
    "    print(f\"Most accurate order is {3}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[3]:\n",
    "    print(f\"Most accurate order is {4}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[4]:\n",
    "    print(f\"Most accurate order is {5}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[5]:\n",
    "    print(f\"Most accurate order is {6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accuracte order after 10 tries: <br>\n",
    "1: 0 <br>\n",
    "2: 0 <br>\n",
    "3: 0 <br>\n",
    "4: 1 <br>\n",
    "5: 4 <br>\n",
    "6: 5 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "print(\"split, SMOTE, scale\")\n",
    "\n",
    "for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_smote, y_smote = smote.fit_sample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "#     y_smote_train.reshape(-1,1)\n",
    "#     y_smote_test.reshape(-1,1)\n",
    "\n",
    "#     X_smote_train = X_smote_train.reshape(-1,1)\n",
    "#     y_smote_train = y_smote_train.reshape(-1,1)\n",
    "#     X_smote_test = X_smote_test.reshape(-1,1)\n",
    "#     y_smote_test = y_smote_test.reshape(-1,1)\n",
    "    \n",
    "#     print(X_smote_train_scaled.shape)\n",
    "#     print(y_smote_train_scaled.shape)\n",
    "#     print(X_smote_test_scaled.shape)\n",
    "#     print(y_smote_test_scaled.shape)\n",
    "    \n",
    "    # Create scale for features and label\n",
    "    X_smote_scaler = StandardScaler().fit(X_smote_train)\n",
    "#     y_smote_scaler = StandardScaler().fit(y_smote_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_smote_train_scaled = X_smote_scaler.transform(X_smote_train)\n",
    "    X_smote_test_scaled = X_smote_scaler.transform(X_smote_test)\n",
    "#     y_smote_train_scaled = y_smote_scaler.transform(y_smote_train)\n",
    "#     y_smote_test_scaled = y_smote_scaler.transform(y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "#     classifier = classifier.fit(X=X_smote_train_scaled, y=y_smote_train)\n",
    "#     score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "# classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_smote, y_smote = smote.fit_sample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "#     y_smote_train.reshape(-1,1)\n",
    "#     y_smote_test.reshape(-1,1)\n",
    "\n",
    "#     X_smote_train = X_smote_train.reshape(-1,1)\n",
    "#     y_smote_train = y_smote_train.reshape(-1,1)\n",
    "#     X_smote_test = X_smote_test.reshape(-1,1)\n",
    "#     y_smote_test = y_smote_test.reshape(-1,1)\n",
    "    \n",
    "#     print(X_smote_train_scaled.shape)\n",
    "#     print(y_smote_train_scaled.shape)\n",
    "#     print(X_smote_test_scaled.shape)\n",
    "#     print(y_smote_test_scaled.shape)\n",
    "    \n",
    "    # Create scale for features and label\n",
    "    X_smote_scaler = StandardScaler().fit(X_smote_train)\n",
    "#     y_smote_scaler = StandardScaler().fit(y_smote_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_smote_train_scaled = X_smote_scaler.transform(X_smote_train)\n",
    "    X_smote_test_scaled = X_smote_scaler.transform(X_smote_test)\n",
    "#     y_smote_train_scaled = y_smote_scaler.transform(y_smote_train)\n",
    "#     y_smote_test_scaled = y_smote_scaler.transform(y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train_scaled, y=y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "#     classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "#     score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "# classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(machine_ready_stroke_data.corr(),cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix\n",
    "confusion_matrix(score,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the SMOTE parameter k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "k_neighbors_arguments = np.arange(1, 102, 10)\n",
    "\n",
    "for k_neighbors_argument in k_neighbors_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=k_neighbors_argument)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the k_neighbor parameter to {k_neighbors_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the train_test_split parameter test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "test_size_arguments = np.arange(0.05, 0.5, 0.05)\n",
    "\n",
    "for test_size_argument in test_size_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = test_size_argument, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the train_test_split parameter to {test_size_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the train_test_split parameter random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "random_state_arguments = np.arange(1, 10, 1)\n",
    "\n",
    "for random_state_argument in random_state_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the random_state parameter to {random_state_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier() parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the DecisionTreeClassifier() parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "max_depth_arguments = np.arange(1, 102, 10)\n",
    "\n",
    "for max_depth_argument in max_depth_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the max_depth parameter to {max_depth_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the DecisionTreeClassifier() parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "max_nodes_arguments = np.arange(2, 153, 10)\n",
    "\n",
    "for max_nodes_argument in max_nodes_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=max_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the max_node parameter to {max_nodes_argument} yields an accuracy of {score}\")\n",
    "\n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a better idea of what impact each parameter does, we will try one final test below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.85, k_neighbors=60)\n",
    "X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "\n",
    "y_smote = y_smote.reshape(-1,1)\n",
    "    \n",
    "# Split the data into training and testing sets\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "\n",
    "# Create, fit, and score the decision tree classifier\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=100, max_leaf_nodes=100)\n",
    "classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "score = classifier.score(X_smote_test, y_smote_test)\n",
    "\n",
    "print(score, \"\\n\")\n",
    "print(classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_smote)\n",
    "\n",
    "\n",
    "joblib.dump(standard_scaler, \"../web_development/standard_scaler.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "feature_names = [\"age\",\n",
    "                 \"average_glucose_levels\",\n",
    "                 \"bmi\",\n",
    "                 \"hypertension_0\",\n",
    "                 \"hypertension_1\",\n",
    "                 \"heart_disease_0\",\n",
    "                 \"heart_disease_1\",\n",
    "                 \"ever_married_No\",\n",
    "                 \"ever_married_Yes\",\n",
    "                 \"work_type_Self-employed\",\n",
    "                 \"work_type_children\",\n",
    "                 \"work_type_other\",\n",
    "                 \"smoking_status_formerly_smoked\",\n",
    "                 \"smoking_status_never_smoked\",\n",
    "                 \"smoking_status_smokes\"\n",
    "                ]\n",
    "class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"]\n",
    "\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                      feature_names=feature_names,\n",
    "                      class_names=class_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out final model\n",
    "import pickle\n",
    "\n",
    "file_name = \"../web_development/stroke_predictor.model\"\n",
    "pickle.dump(classifier, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create scale for features and label\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Scale features and labels\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = []\n",
    "# models.append((\"LR\", LogisticRegression()))\n",
    "# models.append((\"CART\", DecisionTreeClassifier()))\n",
    "# models.append((\"CART\", RandomForestClassifier()))\n",
    "# models.append((\"SVM\", SVC()))\n",
    "# models.append((\"NB\", GaussianNB()))\n",
    "\n",
    "# from sklearn import model_selection\n",
    "\n",
    "# # Evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "\n",
    "# for name, model in models:\n",
    "#     kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "#     cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(f\"{name}: {cv_results.mean()}, {cv_results.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at this\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# decision_tree_data = tree.export_graphviz(\n",
    "#   classifier,\n",
    "#   out_file=None,\n",
    "#   feature_names=[\"age\",\n",
    "#                  \"average_glucose_levels\",\n",
    "#                  \"bmi\",\n",
    "#                  \"hypertension_0\",\n",
    "#                  \"hypertension_1\",\n",
    "#                  \"heart_disease_0\",\n",
    "#                  \"heart_disease_1\",\n",
    "#                  \"ever_married_No\",\n",
    "#                  \"ever_married_Yes\",\n",
    "#                  \"work_type_Self-employed\",\n",
    "#                  \"work_type_children\",\n",
    "#                  \"work_type_other\",\n",
    "#                  \"smoking_status_formerly_smoked\",\n",
    "#                  \"smoking_status_never_smoked\",\n",
    "#                  \"smoking_status_smokes\"\n",
    "#                 ],\n",
    "#     class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"],\n",
    "#     filled=True,\n",
    "#     rounded=False\n",
    "# )\n",
    "\n",
    "# graph = graphviz.Source(decision_tree_data)\n",
    "# #graph\n",
    "\n",
    "# #graph[size=\"7.75,10.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "decision_tree_data = tree.export_graphviz(\n",
    "  classifier,\n",
    "  out_file=None,\n",
    "  feature_names=[\"age\",\n",
    "                 \"average_glucose_levels\",\n",
    "                 \"bmi\",\n",
    "                 \"hypertension_0\",\n",
    "                 \"hypertension_1\",\n",
    "                 \"heart_disease_0\",\n",
    "                 \"heart_disease_1\",\n",
    "                 \"ever_married_No\",\n",
    "                 \"ever_married_Yes\",\n",
    "                 \"work_type_Self-employed\",\n",
    "                 \"work_type_children\",\n",
    "                 \"work_type_other\",\n",
    "                 \"smoking_status_formerly_smoked\",\n",
    "                 \"smoking_status_never_smoked\",\n",
    "                 \"smoking_status_smokes\"\n",
    "                ],\n",
    "    class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"],\n",
    "    filled=True,\n",
    "    rounded=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "graph = graphviz.Source(decision_tree_data)\n",
    "graph\n",
    "\n",
    "#graph[size=\"7.75,10.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tree.export_graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.render(format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing both classes\n",
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=1)\n",
    "rf = rf.fit(X_train, np.array(y_train))\n",
    "rf.score(X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
