{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this project we will build a Machine Learning model to predict whether an indiviudal will have a stroke.  The data used in this project can be found on kaggle at the following link: https://www.kaggle.com/asaumya/healthcare-data#train_2v.csv\n",
    "\n",
    "# In this notebook, we build and implement our Machine Learning model.  To view our initial data analysis, please see the notebook titled \"Data_Analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file path to our data\n",
    "stoke_data_relevant_features_and_label_file_path = os.path.join(\"..\", \"Data\", \"stroke_data_relevant_features_and_label.csv\")\n",
    "\n",
    "# Create dataframe from local csv file \n",
    "stroke_data_relevant_features_and_label = pd.read_csv(stoke_data_relevant_features_and_label_file_path)\n",
    "\n",
    "# Previe dataframe\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to one hot encode our categorical columns, so we will convert each 0 to \"No,\" and each 1 to \"Yes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 0: 0\n",
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Before we replace 0 and 1 with \"no\" and \"yes\",\n",
    "# we should check to see if either of these numbers are present in the age column\n",
    "number_of_people_age_0 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 0])\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 0: {number_of_people_age_0}\")\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we replace all values of 0 and 1 with \"No\" and \"Yes,\"\n",
    "# we are going to replace ages of 1 with a value of \"Yes\"\n",
    "# We will also replace the binary data in the stroke column with strings.\n",
    "# We will therefore make copies of these rows to put back in the dataframe after our initial replacement\n",
    "\n",
    "copy_of_data = pd.DataFrame()\n",
    "\n",
    "# copy_of_data[\"age\"] = stroke_data_relevant_features_and_label[\"age\"]\n",
    "# copy_of_data[\"stroke\"] = stroke_data_relevant_features_and_label[\"stroke\"]\n",
    "\n",
    "copy_of_data_age = [stroke_data_relevant_features_and_label[\"age\"]]\n",
    "copy_of_data_stroke = [stroke_data_relevant_features_and_label[\"stroke\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n",
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children              NaN   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other              NaN   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other              NaN  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace each 0 with \"No,\" and each 1 with \"Yes.\"\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(0, \"No\", inplace=True)\n",
    "stroke_data_relevant_features_and_label[[\"hypertension\", \"heart_disease\"]].replace(1, \"Yes\", inplace=True)\n",
    "\n",
    "# Preview dataframe after converting binary data to strings\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people of age 1: 34\n"
     ]
    }
   ],
   "source": [
    "# Check to see if either if the values of 1 in the age column were changed\n",
    "number_of_people_age_1 = len(stroke_data_relevant_features_and_label[stroke_data_relevant_features_and_label[\"age\"] == 1])\n",
    "\n",
    "print(f\"Number of people of age 1: {number_of_people_age_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the values in the post-replacement age and stroke columns with the original values\n",
    "# stroke_data_relevant_features_and_label[\"age\"] = copy_of_data_age\n",
    "# stroke_data_relevant_features_and_label[\"stroke\"] = copy_of_data_stroke\n",
    "\n",
    "# # Preview dataframe to confirm values in stroke column were fixed\n",
    "# stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39339\n",
      "1     4061\n",
      "Name: hypertension, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0    41338\n",
      "1     2062\n",
      "Name: heart_disease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm binary data proplerly converted\n",
    "print(stroke_data_relevant_features_and_label[\"hypertension\"].value_counts())\n",
    "print(100*\"-\")\n",
    "print(stroke_data_relevant_features_and_label[\"heart_disease\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>hypertension_0</th>\n",
       "      <th>hypertension_1</th>\n",
       "      <th>heart_disease_0</th>\n",
       "      <th>heart_disease_1</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>work_type_other</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  average_glucose_level   bmi  stroke  hypertension_0  hypertension_1  \\\n",
       "0   3.0                  95.12  18.0       0               1               0   \n",
       "1  58.0                  87.96  39.2       0               0               1   \n",
       "2   8.0                 110.89  17.6       0               1               0   \n",
       "3  70.0                  69.04  35.9       0               1               0   \n",
       "4  14.0                 161.28  19.1       0               1               0   \n",
       "\n",
       "   heart_disease_0  heart_disease_1  ever_married_No  ever_married_Yes  \\\n",
       "0                1                0                1                 0   \n",
       "1                1                0                0                 1   \n",
       "2                1                0                1                 0   \n",
       "3                1                0                0                 1   \n",
       "4                1                0                1                 0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  work_type_other  \\\n",
       "0                        0                   1                0   \n",
       "1                        0                   0                1   \n",
       "2                        0                   0                1   \n",
       "3                        0                   0                1   \n",
       "4                        0                   0                1   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               0                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               1                            0   \n",
       "4                               0                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to one hot encoded data\n",
    "machine_ready_stroke_data = pd.get_dummies(stroke_data_relevant_features_and_label, columns=[\"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"smoking_status\"])\n",
    "machine_ready_stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Maching Learning algorithms will we try out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features and label\n",
    "X = np.array(machine_ready_stroke_data.drop([\"stroke\"], axis=1))\n",
    "y = np.array(machine_ready_stroke_data[\"stroke\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our features and labels, but the data is still imbalanced.  We will try employing SMOTE to handle this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following section, we will run a for-loop to examine what order of SMOTE, split, scale (<em>SSS order</em>) yields the best results.  We will ignore any SSS order that scales before it splits, as this could bias the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE to handle the imbalanced data issue\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import tree to use the DecisionTreeClassifier() algorithm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Iteration 0\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9382740190327207\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9777649769585254\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8609447004608295\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9350801720766523\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.977073732718894\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8724654377880184\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9342328249250423\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9811059907834101\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8997695852534562\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.934428366575414\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9802995391705069\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8626728110599078\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 4\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9278451310129058\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9798387096774194\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8421658986175116\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 5\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9324729500716986\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.979147465437788\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8616359447004608\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 6\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9352757137270239\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9699308755760369\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8605990783410138\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 7\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9332551166731847\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9737327188940093\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8785714285714286\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 8\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9334506583235562\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9716589861751153\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.908410138248848\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 9\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9408160604875505\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9679723502304147\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8589861751152074\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 10\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9375570329813584\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9811059907834101\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8597926267281106\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 11\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9288228392647634\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.977073732718894\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8714285714285714\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 12\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9422500325902751\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9784562211981567\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.841705069124424\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 13\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9387954634337113\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9776497695852534\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8355990783410139\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 14\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9400990744361882\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9759216589861751\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.905184331797235\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 15\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9332551166731847\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9808755760368664\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8821428571428571\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 16\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9301916308173641\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9819124423963134\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8629032258064516\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 17\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9378829357319776\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.977188940092166\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8589861751152074\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 18\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9352105331769001\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9631336405529954\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8661290322580645\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 19\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9392517272845783\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9737327188940093\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8390552995391705\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 20\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9388606439838352\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9763824884792627\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8473502304147466\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 21\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9303871724677356\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9693548387096774\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8836405529953917\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 22\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9357319775778907\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9793778801843318\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.9035714285714286\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 23\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9383391995828445\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9746543778801844\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8647465437788019\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 24\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9382088384825968\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9778801843317972\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8495391705069124\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 25\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9367096858297485\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9805299539170507\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8535714285714285\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 26\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9318211445704602\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9732718894009217\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8503456221198157\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 27\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9354712553773954\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9707373271889401\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.851036866359447\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 28\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9368400469299961\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9824884792626728\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.830184331797235\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 29\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9395776300351975\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9790322580645161\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8487327188940093\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 30\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9359926997783862\n",
      "2. split, SMOTE, scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9820276497695852\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8589861751152074\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 31\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9386651023334637\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9756912442396314\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8577188940092166\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 32\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9367748663798723\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9800691244239631\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8591013824884792\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 33\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9341024638247947\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9744239631336405\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8899769585253456\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 34\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9371659496806153\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9820276497695852\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8540322580645161\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 35\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9420544909399036\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9793778801843318\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8629032258064516\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 36\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9362534219788815\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9768433179723502\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8461981566820277\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 37\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9415982270890366\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9756912442396314\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8650921658986175\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 38\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9337113805240517\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9786866359447005\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8619815668202765\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 39\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.939382088384826\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9788018433179724\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8599078341013825\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 40\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9299960891669926\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9756912442396314\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8951612903225806\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 41\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9356667970277669\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9802995391705069\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8920506912442396\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 42\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9378829357319776\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9813364055299539\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8897465437788018\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 43\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9397079911354452\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9773041474654378\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8667050691244239\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 44\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9269977838612958\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9709677419354839\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8720046082949309\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 45\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9308434363186026\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9702764976958526\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8638248847926268\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 46\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9301916308173641\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9773041474654378\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8566820276497696\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 47\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9349498109764046\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.970852534562212\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8588709677419355\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 48\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9391865467344545\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9808755760368664\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8570276497695852\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 49\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9368400469299961\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9776497695852534\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8470046082949308\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "The most accurate order (highest average accuracy) is order 2, with an average accuracy of 0.9767096774193549\n",
      "The most stable order (lowest standard deviation) is order 1, with a standard deviation of 0.003739661951369565\n",
      "\n",
      "The least accurate order (least average accuracy) is order 3, with an average accuracy of 0.864536866359447\n",
      "The least stable order (highest standard deviation) is order 3, with a standard deviation of 0.01834873635664882\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We want to determine which order of SMOTE, split, scale (SSS order) is best for this model\n",
    "# We will use the mean and stdev methods of the statistics library,\n",
    "# to find out which SSS order yields the highest average accuracy, and which order is the most stable (lowest standard deviation)\n",
    "from statistics import mean, stdev\n",
    "\n",
    "# Define variables holding the value for the each argument,\n",
    "# in order to easily change it in multiple places\n",
    "\n",
    "## SMOTE() parameters\n",
    "sampling_strategy_argument = 0.80\n",
    "k_neighbors_argument = 18\n",
    "\n",
    "## train_test_split() parameters\n",
    "test_size_argument = 0.2\n",
    "random_state_argument = 3\n",
    "\n",
    "## DecionTreeClassifier() parameters\n",
    "max_depth_argument = 30\n",
    "max_leaf_nodes_argument = 60\n",
    "\n",
    "# For every iteration in the loop,\n",
    "# we will append the accuracy of the current SSS order to it's own distinct list\n",
    "# After the loop has finished, we will calculate the average of each list\n",
    "# The list with the highest average we will call \"the most accuracte (on average)\"\n",
    "# we will also calculate the standard deviation of each list\n",
    "# The list with the lowest standard deviation we will call \"the most stable\"\n",
    "SSS_order_1_list = []\n",
    "SSS_order_2_list = []\n",
    "SSS_order_3_list = []\n",
    "\n",
    "# Define an iterator \n",
    "i = 1\n",
    "print(i)\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    # Print the current iteration of the loop,\n",
    "    # in case we use a large number of iterations\n",
    "    print(f\"Iteration {i}\")\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"1. SMOTE, split, scale\")\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_SMOTE_train_scaled = X_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_scaler.transform(X_SMOTE_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_1 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 1\n",
    "    SSS_order_1_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "    \n",
    "####################################################################################################\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"2. split, SMOTE, scale\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_2 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 2\n",
    "    SSS_order_2_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"3. split, scale, SMOTE\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_3 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 3\n",
    "    SSS_order_3_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "    \n",
    "    # Print a long line with blank lines above and below,\n",
    "    # to easily see where one iteration of the loop ends, and the next starts\n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "    \n",
    "    # Increase the iterator by one\n",
    "    # so that the print statement at the beginning will show we're on the next iteration\n",
    "    i += 1\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Find the average accuracy of each SSS order,\n",
    "# and add each average to a list\n",
    "average_1 = mean(SSS_order_1_list)\n",
    "average_2 = mean(SSS_order_2_list)\n",
    "average_3 = mean(SSS_order_3_list)\n",
    "averages_list = [average_1, average_2, average_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest average accuracy\n",
    "if max(averages_list) == averages_list[0]:\n",
    "    most_accurate_order = 1\n",
    "    average_accuracy_greatest = averages_list[0]\n",
    "    \n",
    "elif max(averages_list) == averages_list[1]:\n",
    "    most_accurate_order = 2\n",
    "    average_accuracy_greatest = averages_list[1]\n",
    "    \n",
    "elif max(averages_list) == averages_list[2]:\n",
    "    most_accurate_order = 3\n",
    "    average_accuracy_greatest = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most accurate order (highest average accuracy) is order {most_accurate_order}, with an average accuracy of {average_accuracy_greatest}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Find the standard deviation of the accuracy of each SSS order,\n",
    "# and add each standard deviation to a list\n",
    "standard_deviation_1 = stdev(SSS_order_1_list)\n",
    "standard_deviation_2 = stdev(SSS_order_2_list)\n",
    "standard_deviation_3 = stdev(SSS_order_3_list)\n",
    "standard_deviations_list = [standard_deviation_1, standard_deviation_2, standard_deviation_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest standard deviation\n",
    "if min(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    most_stable_order = 1\n",
    "    lowest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    most_stable_order = 2\n",
    "    lowest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    most_stable_order = 3\n",
    "    lowest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most stable order (lowest standard deviation) is order {most_stable_order}, with a standard deviation of {lowest_standard_deviation}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Print a blank line to separate the lines showing us the \"best\" orders from the lines showing us the \"worst\" orders\n",
    "print()\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest average accuracy\n",
    "if min(averages_list) == averages_list[0]:\n",
    "    least_accurate_order = 1\n",
    "    average_accuracy_least = averages_list[0]\n",
    "    \n",
    "elif min(averages_list) == averages_list[1]:\n",
    "    least_accurate_order = 2\n",
    "    average_accuracy_least = averages_list[1]\n",
    "    \n",
    "elif min(averages_list) == averages_list[2]:\n",
    "    least_accurate_order = 3\n",
    "    average_accuracy_least = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least accurate order (least average accuracy) is order {least_accurate_order}, with an average accuracy of {average_accuracy_least}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest standard deviation\n",
    "if max(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    least_stable_order = 1\n",
    "    greatest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    least_stable_order = 2\n",
    "    greatest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    least_stable_order = 3\n",
    "    greatest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least stable order (highest standard deviation) is order {least_stable_order}, with a standard deviation of {greatest_standard_deviation}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################################################################\n",
    "# # IGNORE THIS CELL\n",
    "# ###################################################################################################\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # We want to determine which order of SMOTE, split, scale is best for this model\n",
    "# # We will use the mode and stdev methods of the statistics library,\n",
    "# # to find out which order yields the highest accuracy, and which order is the most stable (lowest standard deviation)\n",
    "# from statistics import mode, stdev\n",
    "\n",
    "# # most_stable_orders = []\n",
    "# # standard_deviations = []\n",
    "\n",
    "# # Define variables holding the value for the each argument,\n",
    "# # in order to easily change it in multiple places\n",
    "\n",
    "# ## SMOTE() parameters\n",
    "# sampling_strategy_argument = 0.80\n",
    "# k_neighbors_argument = 18\n",
    "\n",
    "# ## train_test_split() parameters\n",
    "# test_size_argument = 0.2\n",
    "# random_state_argument = 3\n",
    "\n",
    "# ## DecionTreeClassifier() parameters\n",
    "# max_depth_argument = 30\n",
    "# max_leaf_nodes_argument = 60\n",
    "\n",
    "# # For every iteration in the loop, we will store which value yielded the highest accuracy\n",
    "# # After the loop has finished, we will calculate the mode of the list,\n",
    "# # to determine which order yields the highest accuracy most often\n",
    "# most_accurate_orders = []\n",
    "\n",
    "# for i in range(6):\n",
    "#     print(\"1. split, SMOTE, scale\")\n",
    "#     accuracies_list = []\n",
    "        \n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "#     # Use SMOTE to handle class imbalance\n",
    "#     smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "#     X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "#     y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "#     # Create scaler for features and label\n",
    "#     X_train_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "#     X_test_scaler = StandardScaler().fit(X_test)\n",
    "# #     y_scaler = StandardScaler().fit(y_train_SMOTE)\n",
    "    \n",
    "#     # Scale features and labels\n",
    "#     X_train_SMOTE_scaled = X_train_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "#     X_test_scaled = X_test_scaler.transform(X_test)\n",
    "# #     y_train_SMOTE_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "#     classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "#     score = classifier.score(X_test_scaled, y_test)\n",
    "#     accuracies_list.append(score)\n",
    "    \n",
    "#     # Print a list of accuracies based on the current argument\n",
    "#     print(f\"Accuracy: {score}\")\n",
    "\n",
    "# #     average_accuracy = sum(scores)/len(scores)\n",
    "# #     average_accuracies.append(average_accuracy)\n",
    "# #     standard_deviation = np.std(scores)\n",
    "# #     print(f\"Average accuracy: {average_accuracy}\")\n",
    "# #     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "#     ####################################################################################################\n",
    "\n",
    "#     print(\"2. split, scale, SMOTE\")\n",
    "#     scores = []\n",
    "        \n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "#     # Create scaler for features and label\n",
    "#     X_train_scaler = StandardScaler().fit(X_train)\n",
    "#     X_test_scaler = StandardScaler().fit(X_test)\n",
    "# #     y_scaler = StandardScaler().fit(y_train)\n",
    "    \n",
    "#     # Scale features and labels\n",
    "#     X_train_scaled = X_train_scaler.transform(X_train)\n",
    "#     X_test_scaled = X_test_scaler.transform(X_test)\n",
    "# #     y_train_scaled = y_scaler.transform(y_train)\n",
    "\n",
    "#     # Use SMOTE to handle class imbalance\n",
    "#     smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "#     X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "#     y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "#     classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "#     score = classifier.score(X_test_scaled, y_test)\n",
    "#     accuracies_list.append(score)\n",
    "    \n",
    "#     # Print a list of accuracies based on the current argument\n",
    "#     print(f\"Accuracy: {score}\")\n",
    "        \n",
    "# #     average_accuracy = sum(scores)/len(scores)\n",
    "# #     average_accuracies.append(average_accuracy)\n",
    "# #     standard_deviation = np.std(scores)\n",
    "# #     print(f\"Average accuracy: {average_accuracy}\")\n",
    "# #     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "#     ####################################################################################################\n",
    "\n",
    "#     print(\"3. SMOTE, split, scale\")\n",
    "#     scores = []\n",
    "        \n",
    "#     # Use SMOTE to handle class imbalance\n",
    "#     smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "#     X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "#     y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "#     # Split the data into training and testing sets\n",
    "#     X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "#     # Create scaler for features and label\n",
    "#     X_SMOTE_train_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "#     X_SMOTE_test_scaler = StandardScaler().fit(X_SMOTE_test)\n",
    "# #     y_scaler = StandardScaler().fit(y_SMOTE_train)\n",
    "    \n",
    "#     # Scale features and labels\n",
    "#     X_SMOTE_train_scaled = X_SMOTE_train_scaler.transform(X_SMOTE_train)\n",
    "#     X_SMOTE_test_scaled = X_SMOTE_test_scaler.transform(X_SMOTE_test)\n",
    "# #     y_SMOTE_train_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "#     classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "#     score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "#     accuracies_list.append(score)\n",
    "    \n",
    "#     # Print a list of accuracies based on the current argument\n",
    "#     print(f\"Accuracy: {score}\")\n",
    "        \n",
    "# #     average_accuracy = sum(scores)/len(scores)\n",
    "# #     average_accuracies.append(average_accuracy)\n",
    "# #     standard_deviation = np.std(scores)\n",
    "# #     print(f\"Average accuracy: {average_accuracy}\")\n",
    "# #     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "#     ####################################################################################################\n",
    "        \n",
    "        \n",
    "#     print(\"4. SMOTE, scale, split\")\n",
    "#     scores = []\n",
    "        \n",
    "#     # Use SMOTE to handle class imbalance\n",
    "#     smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "#     X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "#     y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "#     # Create scaler for features and label\n",
    "#     X_scaler = StandardScaler().fit(X_SMOTE)\n",
    "# #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "#     # Scale features and labels\n",
    "#     X_SMOTE_scaled = X_scaler.transform(X_SMOTE)\n",
    "# #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "    \n",
    "#     # Split the data into training and testing sets\n",
    "#     X_SMOTE_scaled_train, X_SMOTE_scaled_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE_scaled, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "#     classifier = classifier.fit(X=X_SMOTE_scaled_train, y=y_SMOTE_train)\n",
    "#     score = classifier.score(X_test, y_test)\n",
    "#     accuracies_list.append(score)\n",
    "    \n",
    "#     # Print a list of accuracies based on the current argument\n",
    "#     print(f\"Accuracy: {score}\")\n",
    "        \n",
    "# #     average_accuracy = sum(scores)/len(scores)\n",
    "# #     average_accuracies.append(average_accuracy)\n",
    "# #     standard_deviation = np.std(scores)\n",
    "# #     print(f\"Average accuracy: {average_accuracy}\")\n",
    "# #     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "#     ####################################################################################################\n",
    "\n",
    "\n",
    "#     print(\"5. scale, split, SMOTE\")\n",
    "#     scores = []\n",
    "        \n",
    "#     # Create scaler for features and label\n",
    "#     X_scaler = StandardScaler().fit(X)\n",
    "# #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "#     # Scale features and labels\n",
    "#     X_scaled = X_scaler.transform(X)\n",
    "# #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "#     # Use SMOTE to handle class imbalance\n",
    "#     smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "#     X_scaled_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_scaled_train, y_train.ravel())\n",
    "#     y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "#     classifier = classifier.fit(X=X_scaled_train_SMOTE, y=y_train_SMOTE)\n",
    "#     score = classifier.score(X_scaled_test, y_test)\n",
    "#     accuracies_list.append(score)\n",
    "    \n",
    "#     # Print a list of accuracies based on the current argument\n",
    "#     print(f\"Accuracy: {score}\")\n",
    "        \n",
    "# #     average_accuracy = sum(scores)/len(scores)\n",
    "# #     average_accuracies.append(average_accuracy)\n",
    "# #     standard_deviation = np.std(scores)\n",
    "# #     print(f\"Average accuracy: {average_accuracy}\")\n",
    "# #     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "        \n",
    "#     ####################################################################################################\n",
    "\n",
    "#     print(\"6. scale, SMOTE, split\")\n",
    "#     scores = []\n",
    "        \n",
    "#     # Create scaler for features and label\n",
    "#     X_scaler = StandardScaler().fit(X)\n",
    "# #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "    \n",
    "#     # Scale features and labels\n",
    "#     X_scaled = X_scaler.transform(X)\n",
    "# #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "#     # Use SMOTE to handle class imbalance\n",
    "#     smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "#     X_scaled_SMOTE, y_SMOTE = smote.fit_sample(X_scaled, y.ravel())\n",
    "#     y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_scaled_SMOTE_train, X_scaled_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_scaled_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "#     classifier = classifier.fit(X=X_scaled_SMOTE_train, y=y_SMOTE_train)\n",
    "#     score = classifier.score(X_scaled_SMOTE_test, y_SMOTE_test)\n",
    "#     accuracies_list.append(score)\n",
    "    \n",
    "#     # Print a list of accuracies based on the current argument\n",
    "#     print(f\"Accuracy: {score}\")  \n",
    "        \n",
    "# #     average_accuracy = sum(scores)/len(scores)\n",
    "# #     average_accuracies.append(average_accuracy)\n",
    "# #     standard_deviation = np.std(scores)\n",
    "# #     print(f\"Average accuracy: {average_accuracy}\")\n",
    "# #     print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "\n",
    "#     ####################################################################################################\n",
    "\n",
    "#     print()\n",
    "    \n",
    "#     if max(accuracies_list) == accuracies_list[0]:\n",
    "#         print(\"Most accurate order is 1: split, SMOTE, scale\")\n",
    "#         most_accurate_orders.append(1)\n",
    "        \n",
    "#     elif max(accuracies_list) == accuracies_list[1]:\n",
    "#         print(\"Most accurate order is 2: split, scale, SMOTE\")\n",
    "#         most_accurate_orders.append(2)\n",
    "        \n",
    "#     elif max(accuracies_list) == accuracies_list[2]:\n",
    "#         print(\"Most accurate order is 3: SMOTE, split, scale\")\n",
    "#         most_accurate_orders.append(3)\n",
    "        \n",
    "#     elif max(accuracies_list) == accuracies_list[3]:\n",
    "#         print(\"Most accurate order is 4: SMOTE, scale, split\")\n",
    "#         most_accurate_orders.append(4)\n",
    "        \n",
    "#     elif max(accuracies_list) == accuracies_list[4]:\n",
    "#         print(\"Most accurate order is 5: scale, split, SMOTE\")\n",
    "#         most_accurate_orders.append(5)\n",
    "        \n",
    "#     elif max(accuracies_list) == accuracies_list[5]:\n",
    "#         print(\"Most accurate order is 6: scale, SMOTE, split\")\n",
    "#         most_accurate_orders.append(6)\n",
    "    \n",
    "#     print()\n",
    "#     print(100*\"-\")\n",
    "#     print()\n",
    "    \n",
    "# most_accurate_order = mode(most_accurate_orders)        \n",
    "# print(f\"Order number {most_accurate_order} was the most accurate the highest number of times.\")\n",
    "# # print(f\"Order number {} was the most stable (lowest standard deviation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "\n",
    "stdev([1, 4, 6, 7, 3, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "average_accuracies = []\n",
    "most_accurate_orders = []\n",
    "most_stable_orders = []\n",
    "standard_deviations = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"1. split, SMOTE, scale\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "        X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_train_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "        X_test_scaler = StandardScaler().fit(X_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_train_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_train_SMOTE_scaled = X_train_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "        X_test_scaled = X_test_scaler.transform(X_test)\n",
    "    #     y_train_SMOTE_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_test_scaled, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "    #     # Create, fit, and score the decision tree classifier\n",
    "    #     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    #     classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    #     score = classifier.score(X_smote_test, y_smote_test)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"2. split, scale, SMOTE\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_train_scaler = StandardScaler().fit(X_train)\n",
    "        X_test_scaler = StandardScaler().fit(X_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_train)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_train_scaled = X_train_scaler.transform(X_train)\n",
    "        X_test_scaled = X_test_scaler.transform(X_test)\n",
    "    #     y_train_scaled = y_scaler.transform(y_train)\n",
    "\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "        X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_test_scaled, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"3. SMOTE, split, scale\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_SMOTE_train_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "        X_SMOTE_test_scaler = StandardScaler().fit(X_SMOTE_test)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE_train)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_SMOTE_train_scaled = X_SMOTE_train_scaler.transform(X_SMOTE_train)\n",
    "        X_SMOTE_test_scaled = X_SMOTE_test_scaler.transform(X_SMOTE_test)\n",
    "    #     y_SMOTE_train_scaled = y_scaler.transform(y_train_SMOTE)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "        \n",
    "    print(\"4. SMOTE, scale, split\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X_SMOTE)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_SMOTE_scaled = X_scaler.transform(X_SMOTE)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_SMOTE_scaled_train, X_SMOTE_scaled_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE_scaled, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_SMOTE_scaled_train, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "\n",
    "    print(\"5. scale, split, SMOTE\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_scaled = X_scaler.transform(X)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y, random_state=3)\n",
    "        \n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_scaled_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_scaled_train, y_train.ravel())\n",
    "        y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_scaled_train_SMOTE, y=y_train_SMOTE)\n",
    "        score = classifier.score(X_scaled_test, y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "        \n",
    "    ####################################################################################################\n",
    "\n",
    "    print(\"6. scale, SMOTE, split\")\n",
    "    scores = []\n",
    "    for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "        \n",
    "        # Create scaler for features and label\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "    #     y_scaler = StandardScaler().fit(y_SMOTE)\n",
    "        \n",
    "        # Scale features and labels\n",
    "        X_scaled = X_scaler.transform(X)\n",
    "    #     y_SMOTE_scaled = y_scaler.transform(y_SMOTE)\n",
    "\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=2)\n",
    "        X_scaled_SMOTE, y_SMOTE = smote.fit_sample(X_scaled, y.ravel())\n",
    "        y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_scaled_SMOTE_train, X_scaled_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_scaled_SMOTE, y_SMOTE, random_state=3)\n",
    "        \n",
    "        # Create, fit, and score the decision tree classifier\n",
    "        classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "        classifier = classifier.fit(X=X_scaled_SMOTE_train, y=y_SMOTE_train)\n",
    "        score = classifier.score(X_scaled_SMOTE_test, y_SMOTE_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Print a list of accuracies based on the current argument\n",
    "        print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")  \n",
    "        \n",
    "    average_accuracy = sum(scores)/len(scores)\n",
    "    average_accuracies.append(average_accuracy)\n",
    "    standard_deviation = np.std(scores)\n",
    "    print(f\"Average accuracy: {average_accuracy}\")\n",
    "    print(f\"Standard Deviation of accuracy: {standard_deviation}\")\n",
    "    print()\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    print()\n",
    "\n",
    "    if max(average_accuracies) == average_accuracies[0]:\n",
    "        print(\"Most accurate order (on average) is 1: split, SMOTE, scale\")\n",
    "#         most_accurate_orders.append(1)\n",
    "        most_accurate_order = 1\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[1]:\n",
    "        print(\"Most accurate order (on average) is 2: split, scale, SMOTE\")\n",
    "#         most_accurate_orders.append(2)\n",
    "        most_accurate_order = 2\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[2]:\n",
    "        print(\"Most accurate order (on average) is 3: SMOTE, split, scale\")\n",
    "#         most_accurate_orders.append(3)\n",
    "        most_accurate_order = 3\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[3]:\n",
    "        print(\"Most accurate order (on average) is 4: SMOTE, scale, split\")\n",
    "#         most_accurate_orders.append(4)\n",
    "        most_accurate_order = 4\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[4]:\n",
    "        print(\"Most accurate order (on average) is 5: scale, split, SMOTE\")\n",
    "#         most_accurate_orders.append(5)\n",
    "        most_accurate_order = 5\n",
    "        \n",
    "    elif max(average_accuracies) == average_accuracies[5]:\n",
    "        print(\"Most accurate order (on average) is 6: scale, SMOTE, split\")\n",
    "#         most_accurate_orders.append(6)\n",
    "        most_accurate_order = 6\n",
    "        \n",
    "print(f\"Order number {most_accurate_order} was the most accurate the highest number of times.\")\n",
    "# print(f\"Order number {} was the most stable (lowest standard deviation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracies\n",
    "\n",
    "if max(average_accuracies) == average_accuracies[0]:\n",
    "    print(f\"Most accurate order is {1}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[1]:\n",
    "    print(f\"Most accurate order is {2}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[2]:\n",
    "    print(f\"Most accurate order is {3}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[3]:\n",
    "    print(f\"Most accurate order is {4}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[4]:\n",
    "    print(f\"Most accurate order is {5}\")\n",
    "    \n",
    "elif max(average_accuracies) == average_accuracies[5]:\n",
    "    print(f\"Most accurate order is {6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accuracte order after 10 tries: <br>\n",
    "1: 0 <br>\n",
    "2: 0 <br>\n",
    "3: 0 <br>\n",
    "4: 1 <br>\n",
    "5: 4 <br>\n",
    "6: 5 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "print(\"split, SMOTE, scale\")\n",
    "\n",
    "for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_smote, y_smote = smote.fit_sample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "#     y_smote_train.reshape(-1,1)\n",
    "#     y_smote_test.reshape(-1,1)\n",
    "\n",
    "#     X_smote_train = X_smote_train.reshape(-1,1)\n",
    "#     y_smote_train = y_smote_train.reshape(-1,1)\n",
    "#     X_smote_test = X_smote_test.reshape(-1,1)\n",
    "#     y_smote_test = y_smote_test.reshape(-1,1)\n",
    "    \n",
    "#     print(X_smote_train_scaled.shape)\n",
    "#     print(y_smote_train_scaled.shape)\n",
    "#     print(X_smote_test_scaled.shape)\n",
    "#     print(y_smote_test_scaled.shape)\n",
    "    \n",
    "    # Create scale for features and label\n",
    "    X_smote_scaler = StandardScaler().fit(X_smote_train)\n",
    "#     y_smote_scaler = StandardScaler().fit(y_smote_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_smote_train_scaled = X_smote_scaler.transform(X_smote_train)\n",
    "    X_smote_test_scaled = X_smote_scaler.transform(X_smote_test)\n",
    "#     y_smote_train_scaled = y_smote_scaler.transform(y_smote_train)\n",
    "#     y_smote_test_scaled = y_smote_scaler.transform(y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "#     classifier = classifier.fit(X=X_smote_train_scaled, y=y_smote_train)\n",
    "#     score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "# classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "sampling_strategy_arguments = np.arange(0.6, 1, 0.05)\n",
    "\n",
    "for sampling_strategy_argument in sampling_strategy_arguments:\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=8)\n",
    "    X_smote, y_smote = smote.fit_sample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "#     y_smote_train.reshape(-1,1)\n",
    "#     y_smote_test.reshape(-1,1)\n",
    "\n",
    "#     X_smote_train = X_smote_train.reshape(-1,1)\n",
    "#     y_smote_train = y_smote_train.reshape(-1,1)\n",
    "#     X_smote_test = X_smote_test.reshape(-1,1)\n",
    "#     y_smote_test = y_smote_test.reshape(-1,1)\n",
    "    \n",
    "#     print(X_smote_train_scaled.shape)\n",
    "#     print(y_smote_train_scaled.shape)\n",
    "#     print(X_smote_test_scaled.shape)\n",
    "#     print(y_smote_test_scaled.shape)\n",
    "    \n",
    "    # Create scale for features and label\n",
    "    X_smote_scaler = StandardScaler().fit(X_smote_train)\n",
    "#     y_smote_scaler = StandardScaler().fit(y_smote_train)\n",
    "    \n",
    "    # Scale features and labels\n",
    "    X_smote_train_scaled = X_smote_scaler.transform(X_smote_train)\n",
    "    X_smote_test_scaled = X_smote_scaler.transform(X_smote_test)\n",
    "#     y_smote_train_scaled = y_smote_scaler.transform(y_smote_train)\n",
    "#     y_smote_test_scaled = y_smote_scaler.transform(y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train_scaled, y=y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "#     # Create, fit, and score the decision tree classifier\n",
    "#     classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "#     classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "#     score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the sampling_strategy parameter to {sampling_strategy_argument} yields an accuracy of {score}\")\n",
    "\n",
    "# classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(machine_ready_stroke_data.corr(),cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix\n",
    "confusion_matrix(score,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the SMOTE parameter k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "k_neighbors_arguments = np.arange(1, 102, 10)\n",
    "\n",
    "for k_neighbors_argument in k_neighbors_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=k_neighbors_argument)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the k_neighbor parameter to {k_neighbors_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the train_test_split parameter test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "test_size_arguments = np.arange(0.05, 0.5, 0.05)\n",
    "\n",
    "for test_size_argument in test_size_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = test_size_argument, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the train_test_split parameter to {test_size_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the train_test_split parameter random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "random_state_arguments = np.arange(1, 10, 1)\n",
    "\n",
    "for random_state_argument in random_state_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the random_state parameter to {random_state_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier() parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the DecisionTreeClassifier() parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "max_depth_arguments = np.arange(1, 102, 10)\n",
    "\n",
    "for max_depth_argument in max_depth_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=max_depth_argument, max_leaf_nodes=10)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the max_depth parameter to {max_depth_argument} yields an accuracy of {score}\")\n",
    "    \n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we examine how accuracy changes when adjusting the DecisionTreeClassifier() parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of arguments to iteratively try out\n",
    "max_nodes_arguments = np.arange(2, 153, 10)\n",
    "\n",
    "for max_nodes_argument in max_nodes_arguments:\n",
    "    smote = SMOTE(sampling_strategy=0.85, k_neighbors=4)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "    \n",
    "    # Create, fit, and score the decision tree classifier\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=10, max_leaf_nodes=max_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "    score = classifier.score(X_smote_test, y_smote_test)\n",
    "    \n",
    "    # Print a list of accuracies based on the current argument\n",
    "    print(f\"Setting the max_node parameter to {max_nodes_argument} yields an accuracy of {score}\")\n",
    "\n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a better idea of what impact each parameter does, we will try one final test below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.85, k_neighbors=60)\n",
    "X_smote, y_smote = smote.fit_resample(X, y.ravel())\n",
    "\n",
    "y_smote = y_smote.reshape(-1,1)\n",
    "    \n",
    "# Split the data into training and testing sets\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state=3)\n",
    "\n",
    "# Create, fit, and score the decision tree classifier\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=100, max_leaf_nodes=100)\n",
    "classifier = classifier.fit(X=X_smote_train, y= y_smote_train)\n",
    "score = classifier.score(X_smote_test, y_smote_test)\n",
    "\n",
    "print(score, \"\\n\")\n",
    "print(classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_smote)\n",
    "\n",
    "\n",
    "joblib.dump(standard_scaler, \"../web_development/standard_scaler.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "feature_names = [\"age\",\n",
    "                 \"average_glucose_levels\",\n",
    "                 \"bmi\",\n",
    "                 \"hypertension_0\",\n",
    "                 \"hypertension_1\",\n",
    "                 \"heart_disease_0\",\n",
    "                 \"heart_disease_1\",\n",
    "                 \"ever_married_No\",\n",
    "                 \"ever_married_Yes\",\n",
    "                 \"work_type_Self-employed\",\n",
    "                 \"work_type_children\",\n",
    "                 \"work_type_other\",\n",
    "                 \"smoking_status_formerly_smoked\",\n",
    "                 \"smoking_status_never_smoked\",\n",
    "                 \"smoking_status_smokes\"\n",
    "                ]\n",
    "class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"]\n",
    "\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                      feature_names=feature_names,\n",
    "                      class_names=class_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out final model\n",
    "import pickle\n",
    "\n",
    "file_name = \"../web_development/stroke_predictor.model\"\n",
    "pickle.dump(classifier, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create scale for features and label\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Scale features and labels\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = []\n",
    "# models.append((\"LR\", LogisticRegression()))\n",
    "# models.append((\"CART\", DecisionTreeClassifier()))\n",
    "# models.append((\"CART\", RandomForestClassifier()))\n",
    "# models.append((\"SVM\", SVC()))\n",
    "# models.append((\"NB\", GaussianNB()))\n",
    "\n",
    "# from sklearn import model_selection\n",
    "\n",
    "# # Evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "\n",
    "# for name, model in models:\n",
    "#     kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "#     cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(f\"{name}: {cv_results.mean()}, {cv_results.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at this\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# decision_tree_data = tree.export_graphviz(\n",
    "#   classifier,\n",
    "#   out_file=None,\n",
    "#   feature_names=[\"age\",\n",
    "#                  \"average_glucose_levels\",\n",
    "#                  \"bmi\",\n",
    "#                  \"hypertension_0\",\n",
    "#                  \"hypertension_1\",\n",
    "#                  \"heart_disease_0\",\n",
    "#                  \"heart_disease_1\",\n",
    "#                  \"ever_married_No\",\n",
    "#                  \"ever_married_Yes\",\n",
    "#                  \"work_type_Self-employed\",\n",
    "#                  \"work_type_children\",\n",
    "#                  \"work_type_other\",\n",
    "#                  \"smoking_status_formerly_smoked\",\n",
    "#                  \"smoking_status_never_smoked\",\n",
    "#                  \"smoking_status_smokes\"\n",
    "#                 ],\n",
    "#     class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"],\n",
    "#     filled=True,\n",
    "#     rounded=False\n",
    "# )\n",
    "\n",
    "# graph = graphviz.Source(decision_tree_data)\n",
    "# #graph\n",
    "\n",
    "# #graph[size=\"7.75,10.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "decision_tree_data = tree.export_graphviz(\n",
    "  classifier,\n",
    "  out_file=None,\n",
    "  feature_names=[\"age\",\n",
    "                 \"average_glucose_levels\",\n",
    "                 \"bmi\",\n",
    "                 \"hypertension_0\",\n",
    "                 \"hypertension_1\",\n",
    "                 \"heart_disease_0\",\n",
    "                 \"heart_disease_1\",\n",
    "                 \"ever_married_No\",\n",
    "                 \"ever_married_Yes\",\n",
    "                 \"work_type_Self-employed\",\n",
    "                 \"work_type_children\",\n",
    "                 \"work_type_other\",\n",
    "                 \"smoking_status_formerly_smoked\",\n",
    "                 \"smoking_status_never_smoked\",\n",
    "                 \"smoking_status_smokes\"\n",
    "                ],\n",
    "    class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"],\n",
    "    filled=True,\n",
    "    rounded=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "graph = graphviz.Source(decision_tree_data)\n",
    "graph\n",
    "\n",
    "#graph[size=\"7.75,10.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tree.export_graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.render(format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing both classes\n",
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=1)\n",
    "rf = rf.fit(X_train, np.array(y_train))\n",
    "rf.score(X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
